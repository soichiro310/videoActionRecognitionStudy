{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T02:50:00.716495Z",
     "start_time": "2019-07-05T02:49:59.480920Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping, CSVLogger\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import sys\n",
    "import pprint\n",
    "import numpy\n",
    "\n",
    "#pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自前で用意したライブラリインポート ＋ データセットパス指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T02:50:01.367138Z",
     "start_time": "2019-07-05T02:50:01.287768Z"
    }
   },
   "outputs": [],
   "source": [
    "from data import DataSet\n",
    "from cnn_models import ResearchModels\n",
    "import time\n",
    "\n",
    "HOMEDIR = os.path.expanduser(\"~\") + '/'\n",
    "DATA_PATH = HOMEDIR + \"dataset/UCF101/data_file.csv\"\n",
    "FRAME_DIR = HOMEDIR + \"dataset/UCF101/UCF-101_frame\"\n",
    "TRAIN_DIR = FRAME_DIR + \"/train\"\n",
    "TEST_DIR = FRAME_DIR + \"/test\"\n",
    "\n",
    "data = DataSet(data_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習を行う関数(参考コードそのまま)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T02:50:04.023203Z",
     "start_time": "2019-07-05T02:50:04.000102Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(data_type, seq_length, model, saved_model=None,\n",
    "          class_limit=None, image_shape=None,\n",
    "          load_to_memory=False, batch_size=32, nb_epoch=100):\n",
    "    # Helper: Save the model.\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=os.path.join('data', 'checkpoints', model + '-' + data_type + \\\n",
    "            '.{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "    # Helper: TensorBoard\n",
    "    tb = TensorBoard(log_dir=os.path.join('data', 'logs', model))\n",
    "\n",
    "    # Helper: Stop when we stop learning.\n",
    "    early_stopper = EarlyStopping(patience=5)\n",
    "\n",
    "    # Helper: Save results.\n",
    "    timestamp = time.time()\n",
    "    csv_logger = CSVLogger(os.path.join('data', 'logs', model + '-' + 'training-' + \\\n",
    "        str(timestamp) + '.log'))\n",
    "\n",
    "    # Get the data and process it.\n",
    "    if image_shape is None:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length,\n",
    "            class_limit=class_limit,\n",
    "            data_path=DATA_PATH\n",
    "        )\n",
    "    else:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length,\n",
    "            class_limit=class_limit,\n",
    "            image_shape=image_shape,\n",
    "            data_path=DATA_PATH\n",
    "        )\n",
    "\n",
    "    # Get samples per epoch.\n",
    "    # Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n",
    "    steps_per_epoch = (len(data.data) * 0.7) // batch_size\n",
    "\n",
    "    if load_to_memory:\n",
    "        # Get data.\n",
    "        X, y = data.get_all_sequences_in_memory('train', data_type, FRAME_DIR)\n",
    "        X_test, y_test = data.get_all_sequences_in_memory('test', data_type, FRAME_DIR)\n",
    "    else:\n",
    "        # Get generators.\n",
    "        generator = data.frame_generator(batch_size, 'train', data_type, FRAME_DIR)\n",
    "        val_generator = data.frame_generator(batch_size, 'test', data_type, FRAME_DIR)\n",
    "\n",
    "    # Get the model.\n",
    "    rm = ResearchModels(len(data.classes), model, seq_length, saved_model)\n",
    "\n",
    "    # Fit!\n",
    "    if load_to_memory:\n",
    "        # Use standard fit.\n",
    "        rm.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, csv_logger],\n",
    "            epochs=nb_epoch)\n",
    "    else:\n",
    "        # Use fit generator.\n",
    "        rm.model.fit_generator(\n",
    "            generator=generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, csv_logger, checkpointer],\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=40,\n",
    "            workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 各種パラメータ設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T03:03:35.221978Z",
     "start_time": "2019-07-05T03:03:35.214102Z"
    }
   },
   "outputs": [],
   "source": [
    "# model can be one of lstm, lrcn, mlp, conv_3d, c3d\n",
    "model = 'conv_3d'\n",
    "saved_model = None  # None or weights file\n",
    "class_limit = None  # int, can be 1-101 or None\n",
    "seq_length = 40\n",
    "load_to_memory = False  # pre-load the sequences into memory\n",
    "batch_size = 24\n",
    "nb_epoch = 10\n",
    "\n",
    "# Chose images or features and image shape based on network.\n",
    "if model in ['conv_3d', 'c3d', 'lrcn']:\n",
    "    data_type = 'images'\n",
    "    image_shape = (80, 80, 3)\n",
    "elif model in ['lstm', 'mlp']:\n",
    "    data_type = 'features'\n",
    "    image_shape = None\n",
    "else:\n",
    "    raise ValueError(\"Invalid model. See train.py for options.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-05T03:03:35.985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Conv3D\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_7 (Conv3D)            (None, 38, 78, 78, 32)    2624      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 38, 39, 39, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 36, 37, 37, 64)    55360     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 36, 18, 18, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 34, 16, 16, 128)   221312    \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 32, 14, 14, 128)   442496    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 32, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 31, 6, 6, 256)     262400    \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 30, 5, 5, 256)     524544    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 30, 2, 2, 256)     0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 30720)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              31458304  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 101)               103525    \n",
      "=================================================================\n",
      "Total params: 34,120,165\n",
      "Trainable params: 34,120,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "Creating train generator with 8596 samples.\n",
      "Creating test generator with 3418 samples.\n",
      "302/350 [========================>.....] - ETA: 1:19 - loss: 4.5931 - acc: 0.0170 - top_k_categorical_accuracy: 0.0701"
     ]
    }
   ],
   "source": [
    " train(data_type, seq_length, model, saved_model=saved_model,\n",
    "          class_limit=class_limit, image_shape=image_shape,\n",
    "          load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-04T10:03:47.634296Z",
     "start_time": "2019-07-04T10:03:44.417Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
