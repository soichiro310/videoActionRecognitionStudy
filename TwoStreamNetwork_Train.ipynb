{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Spatial Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T08:42:17.321685Z",
     "start_time": "2019-07-12T08:42:11.843422Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s-sato/dataset/UCF101/data_file.csv\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from TwoStreamNetwork.spatial.trainModel import get_model, freeze_all_but_top, freeze_all_but_mid_and_top\n",
    "from TwoStreamNetwork.spatial.trainData import DataSet, get_generators\n",
    "import time\n",
    "import os.path\n",
    "from os import makedirs\n",
    "from DataSetPathCall import UCF101_PathCall\n",
    "\n",
    "ucf101 = UCF101_PathCall()\n",
    "\n",
    "print(ucf101.getDataListPath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T08:42:24.343915Z",
     "start_time": "2019-07-12T08:42:17.327024Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import trainSetting \n",
    "\n",
    "trainSetting.GPU_Limit(0.9)\n",
    "#trainSetting.GPU_LimitAllow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T08:42:27.121799Z",
     "start_time": "2019-07-12T08:42:24.347323Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, nb_epoch, generators, callbacks=[]):\n",
    "    train_generator, validation_generator = generators\n",
    "    model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=10,\n",
    "        epochs=nb_epoch,\n",
    "        callbacks=callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T08:42:44.989107Z",
     "start_time": "2019-07-12T08:42:27.124033Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "saved_weights = None\n",
    "class_limit = None  # int, can be 1-101 or None\n",
    "num_of_snip = 1 # number of chunks used for each video\n",
    "image_shape=(224, 224)\n",
    "load_to_memory = False  # pre-load the sequencea in,o memory\n",
    "batch_size = 32\n",
    "nb_epoch = 100\n",
    "name_str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T08:44:29.025977Z",
     "start_time": "2019-07-12T08:42:44.992227Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/checkpoints/1907121742\n",
      "class_limit =  None\n",
      "Found 1788425 images belonging to 101 classes.\n",
      "Found 697865 images belonging to 101 classes.\n",
      "WARNING:tensorflow:From /home/s-sato/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Get local time.\n",
    "time_str = time.strftime(\"%y%m%d%H%M\", time.localtime())\n",
    "\n",
    "if name_str == None:\n",
    "    name_str = time_str\n",
    "\n",
    "# Callbacks: Save the model.\n",
    "directory1 = os.path.join('out', 'checkpoints', name_str)\n",
    "\n",
    "print(directory1)\n",
    "\n",
    "if not os.path.exists(directory1):\n",
    "    os.makedirs(directory1)\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=os.path.join(directory1, '{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "# Callbacks: TensorBoard\n",
    "directory2 = os.path.join('out', 'TB', name_str)\n",
    "if not os.path.exists(directory2):\n",
    "    os.makedirs(directory2)\n",
    "tb = TensorBoard(log_dir=os.path.join(directory2))\n",
    "\n",
    "# Callbacks: Early stoper\n",
    "early_stopper = EarlyStopping(monitor='loss', patience=100)\n",
    "\n",
    "# Callbacks: Save results.\n",
    "directory3 = os.path.join('out', 'logs', name_str)\n",
    "if not os.path.exists(directory3):\n",
    "    os.makedirs(directory3)\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join(directory3, 'training-' + \\\n",
    "    str(timestamp) + '.log'))\n",
    "\n",
    "print(\"class_limit = \", class_limit)\n",
    "\n",
    "if image_shape is None:\n",
    "    data = DataSet(\n",
    "            class_limit=class_limit,\n",
    "            data_path=ucf101.getDataListPath()\n",
    "            )\n",
    "else:\n",
    "    data = DataSet(\n",
    "            image_shape=image_shape,\n",
    "            class_limit=class_limit,\n",
    "            data_path=ucf101.getDataListPath()\n",
    "            )\n",
    "\n",
    "# Get generators.\n",
    "generators = get_generators(data=data, image_shape=image_shape, batch_size=batch_size\n",
    "                            ,trainDir=ucf101.getTrainDir(), validDir=ucf101.getTestDir())\n",
    "\n",
    "# Get the model.\n",
    "model = get_model(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T09:45:13.253231Z",
     "start_time": "2019-07-12T08:44:29.028101Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network from ImageNet weights.\n",
      "Get and train the top layers...\n",
      "WARNING:tensorflow:From /home/s-sato/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 875s 9s/step - loss: 4.2326 - acc: 0.1209 - val_loss: 3.2978 - val_acc: 0.2875\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 397s 4s/step - loss: 3.1993 - acc: 0.2794 - val_loss: 3.4245 - val_acc: 0.2781\n",
      "Epoch 3/10\n",
      "  2/100 [..............................] - ETA: 5:40 - loss: 2.6734 - acc: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.177772). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 291s 3s/step - loss: 2.6215 - acc: 0.3706 - val_loss: 3.1412 - val_acc: 0.3563\n",
      "Epoch 4/10\n",
      "  1/100 [..............................] - ETA: 3:53 - loss: 2.8229 - acc: 0.3125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.106190). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 287s 3s/step - loss: 2.3843 - acc: 0.4234 - val_loss: 2.8215 - val_acc: 0.3500\n",
      "Epoch 5/10\n",
      "  1/100 [..............................] - ETA: 5:49 - loss: 2.1874 - acc: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.235098). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/100 [>.............................] - ETA: 6:50 - loss: 2.4741 - acc: 0.3906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.147431). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 67/100 [===================>..........] - ETA: 1:35 - loss: 2.1430 - acc: 0.4655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.108549). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 293s 3s/step - loss: 2.1514 - acc: 0.4659 - val_loss: 3.5781 - val_acc: 0.3594\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 292s 3s/step - loss: 2.0183 - acc: 0.4884 - val_loss: 2.4872 - val_acc: 0.4500\n",
      "Epoch 7/10\n",
      "  4/100 [>.............................] - ETA: 6:34 - loss: 2.0341 - acc: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.110970). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 302s 3s/step - loss: 1.9760 - acc: 0.4916 - val_loss: 2.9134 - val_acc: 0.4281\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 299s 3s/step - loss: 1.8732 - acc: 0.5238 - val_loss: 3.1769 - val_acc: 0.4156\n",
      "Epoch 9/10\n",
      "  1/100 [..............................] - ETA: 6:00 - loss: 1.5206 - acc: 0.5938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.535921). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/100 [..............................] - ETA: 6:11 - loss: 1.5814 - acc: 0.5625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.319867). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/100 [..............................] - ETA: 6:35 - loss: 1.6905 - acc: 0.5417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.103814). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 297s 3s/step - loss: 1.8667 - acc: 0.5153 - val_loss: 3.0089 - val_acc: 0.3969\n",
      "Epoch 10/10\n",
      " 12/100 [==>...........................] - ETA: 4:58 - loss: 1.9074 - acc: 0.5052"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.101090). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 309s 3s/step - loss: 1.7400 - acc: 0.5459 - val_loss: 2.8605 - val_acc: 0.4125\n"
     ]
    }
   ],
   "source": [
    "if saved_weights is None:\n",
    "    print(\"Loading network from ImageNet weights.\")\n",
    "    print(\"Get and train the top layers...\")\n",
    "    model = freeze_all_but_top(model)\n",
    "    model = train_model(model, 10, generators)\n",
    "else:\n",
    "    print(\"Loading saved model: %s.\" % saved_weights)\n",
    "    model.load_weights(saved_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T10:35:07.127056Z",
     "start_time": "2019-07-12T09:45:13.353610Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get and train the mid layers...\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 302s 3s/step - loss: 1.5371 - acc: 0.6022 - top_k_categorical_accuracy: 0.8384 - val_loss: 2.1495 - val_acc: 0.4844 - val_top_k_categorical_accuracy: 0.7625\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.14948, saving model to out/checkpoints/1907121742/001-2.149.hdf5\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 274s 3s/step - loss: 1.3709 - acc: 0.6341 - top_k_categorical_accuracy: 0.8656 - val_loss: 2.0863 - val_acc: 0.4844 - val_top_k_categorical_accuracy: 0.7469\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.14948 to 2.08629, saving model to out/checkpoints/1907121742/002-2.086.hdf5\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 297s 3s/step - loss: 1.3382 - acc: 0.6550 - top_k_categorical_accuracy: 0.8659 - val_loss: 2.0743 - val_acc: 0.5000 - val_top_k_categorical_accuracy: 0.7750\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.08629 to 2.07432, saving model to out/checkpoints/1907121742/003-2.074.hdf5\n",
      "Epoch 4/10\n",
      "  1/100 [..............................] - ETA: 1:44 - loss: 1.1483 - acc: 0.7500 - top_k_categorical_accuracy: 0.8438"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (1.064031). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/100 [..............................] - ETA: 5:01 - loss: 1.1522 - acc: 0.7344 - top_k_categorical_accuracy: 0.8594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.741309). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/100 [..............................] - ETA: 5:34 - loss: 1.1474 - acc: 0.6979 - top_k_categorical_accuracy: 0.8854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.418586). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  4/100 [>.............................] - ETA: 5:58 - loss: 1.2688 - acc: 0.6797 - top_k_categorical_accuracy: 0.8672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.271423). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  5/100 [>.............................] - ETA: 6:09 - loss: 1.2765 - acc: 0.6687 - top_k_categorical_accuracy: 0.8688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.124259). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 301s 3s/step - loss: 1.2488 - acc: 0.6669 - top_k_categorical_accuracy: 0.8809 - val_loss: 2.1032 - val_acc: 0.5219 - val_top_k_categorical_accuracy: 0.7438\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.07432\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 301s 3s/step - loss: 1.1801 - acc: 0.6884 - top_k_categorical_accuracy: 0.8909 - val_loss: 2.0958 - val_acc: 0.4938 - val_top_k_categorical_accuracy: 0.7719\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.07432\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 291s 3s/step - loss: 1.1112 - acc: 0.7106 - top_k_categorical_accuracy: 0.8975 - val_loss: 1.9529 - val_acc: 0.5125 - val_top_k_categorical_accuracy: 0.7781\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.07432 to 1.95295, saving model to out/checkpoints/1907121742/006-1.953.hdf5\n",
      "Epoch 7/10\n",
      "  1/100 [..............................] - ETA: 2:47 - loss: 0.8758 - acc: 0.8438 - top_k_categorical_accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.412764). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  2/100 [..............................] - ETA: 4:11 - loss: 0.8867 - acc: 0.8125 - top_k_categorical_accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.222339). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 293s 3s/step - loss: 1.0818 - acc: 0.7150 - top_k_categorical_accuracy: 0.8956 - val_loss: 2.0717 - val_acc: 0.4750 - val_top_k_categorical_accuracy: 0.7875\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.95295\n",
      "Epoch 8/10\n",
      "  3/100 [..............................] - ETA: 6:42 - loss: 1.0425 - acc: 0.7083 - top_k_categorical_accuracy: 0.9062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s-sato/anaconda3/lib/python3.7/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.153537). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 301s 3s/step - loss: 1.0769 - acc: 0.7212 - top_k_categorical_accuracy: 0.9025 - val_loss: 2.0699 - val_acc: 0.4594 - val_top_k_categorical_accuracy: 0.7625\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.95295\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 290s 3s/step - loss: 1.0817 - acc: 0.7203 - top_k_categorical_accuracy: 0.9031 - val_loss: 1.9033 - val_acc: 0.4750 - val_top_k_categorical_accuracy: 0.7812\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.95295 to 1.90329, saving model to out/checkpoints/1907121742/009-1.903.hdf5\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 291s 3s/step - loss: 1.0509 - acc: 0.7181 - top_k_categorical_accuracy: 0.9119 - val_loss: 2.0764 - val_acc: 0.4781 - val_top_k_categorical_accuracy: 0.7531\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.90329\n"
     ]
    }
   ],
   "source": [
    "print(\"Get and train the mid layers...\")\n",
    "model = freeze_all_but_mid_and_top(model)\n",
    "model = train_model(model, 10, generators, [tb, early_stopper, csv_logger, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T01:34:44.695256Z",
     "start_time": "2019-07-19T01:34:43.511721Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger, LearningRateScheduler\n",
    "from TwoStreamNetwork.temporal.trainModel import ResearchModels\n",
    "from TwoStreamNetwork.temporal.trainData import DataSet\n",
    "import time\n",
    "import os.path\n",
    "from os import makedirs\n",
    "from DataSetPathCall import UCF101_PathCall\n",
    "\n",
    "ucf101 = UCF101_PathCall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T01:34:44.716804Z",
     "start_time": "2019-07-19T01:34:44.712305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/s-sato/dataset/UCF101/tvl1_flow/data_list.csv\n",
      "/home/s-sato/dataset/UCF101/tvl1_flow\n"
     ]
    }
   ],
   "source": [
    "print(ucf101.getDataListPath())\n",
    "print(ucf101.getOptFlowDir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T01:34:45.460473Z",
     "start_time": "2019-07-19T01:34:45.454687Z"
    }
   },
   "outputs": [],
   "source": [
    "def fixed_schedule(epoch):\n",
    "    initial_lr = 1.e-2\n",
    "    lr = initial_lr\n",
    "\n",
    "    if epoch == 1389:\n",
    "        lr = 0.1 * lr\n",
    "    if epoch == 1944:\n",
    "        lr = 0.1 * lr\n",
    "\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T01:34:52.388299Z",
     "start_time": "2019-07-19T01:34:52.382583Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model = None\n",
    "class_limit = None  # int, can be 1-101 or None\n",
    "num_of_snip = 1 # number of chunks used for each video\n",
    "opt_flow_len = 10 # number of optical flow frames used\n",
    "image_shape=(224, 224)\n",
    "load_to_memory = False  # pre-load the sequences into memory\n",
    "batch_size = 64\n",
    "nb_epoch = 1000\n",
    "name_str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T01:34:54.237050Z",
     "start_time": "2019-07-19T01:34:53.422287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_limit =  None\n",
      "/home/s-sato/dataset/UCF101/tvl1_flow\n"
     ]
    }
   ],
   "source": [
    "# Get local time.\n",
    "time_str = time.strftime(\"%y%m%d%H%M\", time.localtime())\n",
    "\n",
    "if name_str == None:\n",
    "    name_str = time_str\n",
    "\n",
    "# Callbacks: Save the model.\n",
    "directory1 = os.path.join('out', 'checkpoints', name_str)\n",
    "if not os.path.exists(directory1):\n",
    "        os.makedirs(directory1)\n",
    "checkpointer = ModelCheckpoint(\n",
    "        filepath=os.path.join(directory1,\n",
    "                '{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "# Callbacks: TensorBoard\n",
    "directory2 = os.path.join('out', 'TB', name_str)\n",
    "if not os.path.exists(directory2):\n",
    "        os.makedirs(directory2)\n",
    "tb = TensorBoard(log_dir=os.path.join(directory2))\n",
    "\n",
    "# Callbacks: Early stopper.\n",
    "early_stopper = EarlyStopping(monitor='loss', patience=100)\n",
    "\n",
    "# Callbacks: Save results.\n",
    "directory3 = os.path.join('out', 'logs', name_str)\n",
    "if not os.path.exists(directory3):\n",
    "        os.makedirs(directory3)\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join(directory3, 'training-' + \\\n",
    "        str(timestamp) + '.log'))\n",
    "\n",
    "# Learning rate schedule.\n",
    "lr_schedule = LearningRateScheduler(fixed_schedule, verbose=0)\n",
    "\n",
    "print(\"class_limit = \", class_limit)\n",
    "# Get the data and process it.\n",
    "if image_shape is None:\n",
    "    data = DataSet(\n",
    "            num_of_snip=num_of_snip,\n",
    "            opt_flow_len=opt_flow_len,\n",
    "            class_limit=class_limit,\n",
    "            opt_flow_path=ucf101.getOptFlowDir(),\n",
    "            data_path=ucf101.getDataListPath()\n",
    "            )\n",
    "else:\n",
    "    data = DataSet(\n",
    "            num_of_snip=num_of_snip,\n",
    "            opt_flow_len=opt_flow_len,\n",
    "            image_shape=image_shape,\n",
    "            class_limit=class_limit,\n",
    "            opt_flow_path=ucf101.getOptFlowDir(),\n",
    "            data_path=ucf101.getDataListPath()\n",
    "            )\n",
    "\n",
    "# Get samples per epoch.\n",
    "# Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n",
    "steps_per_epoch = (len(data.data_list) * 0.7) // batch_size\n",
    "print(data.opt_flow_path)\n",
    "#print(data.data_list)S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T01:34:54.287205Z",
     "start_time": "2019-07-19T01:34:54.284807Z"
    }
   },
   "outputs": [],
   "source": [
    "#if load_to_memory:\n",
    "#    # Get data.\n",
    "#    X, y = data.get_all_stacks_in_memory('train')\n",
    "#    X_test, y_test = data.get_all_stacks_in_memory('test')\n",
    "#else:\n",
    "# Get generators.\n",
    "generator = data.stack_generator(batch_size, 'train')\n",
    "\n",
    "val_generator = data.stack_generator(batch_size, 'test', name_str=name_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-19T01:34:56.607358Z",
     "start_time": "2019-07-19T01:34:54.997917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:\n",
      "100\n",
      "Loading CNN model for the temporal stream.\n",
      "Input shape:\n",
      "(224, 224, 20)\n",
      "Numer of classes:\n",
      "100\n",
      "WARNING:tensorflow:From /home/s-sato/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/s-sato/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 96)      94176     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 112, 112, 96)      384       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 112, 112, 96)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              8390656   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               204900    \n",
      "=================================================================\n",
      "Total params: 117,969,092\n",
      "Trainable params: 117,968,900\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get the model.\n",
    "temporal_cnn = ResearchModels(nb_classes=len(data.classes), num_of_snip=num_of_snip, \n",
    "                              opt_flow_len=opt_flow_len, image_shape=image_shape, \n",
    "                              saved_model=saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-20T12:11:13.824200Z",
     "start_time": "2019-07-19T01:34:56.618638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/s-sato/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "\n",
      "Creating train generator with 9437 samples.\n",
      "\n",
      "\n",
      "Creating test generator with 3755 samples.\n",
      "\n",
      "144/144 [==============================] - 673s 5s/step - loss: 4.6209 - acc: 0.0129 - top_k_categorical_accuracy: 0.0586 - val_loss: 4.5936 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.0938\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.59360, saving model to out/checkpoints/1907191034/001-4.594.hdf5\n",
      "Epoch 2/1000\n",
      "144/144 [==============================] - 640s 4s/step - loss: 4.5955 - acc: 0.0122 - top_k_categorical_accuracy: 0.0586 - val_loss: 4.5545 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.1094\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.59360 to 4.55452, saving model to out/checkpoints/1907191034/002-4.555.hdf5\n",
      "Epoch 3/1000\n",
      "144/144 [==============================] - 633s 4s/step - loss: 4.5739 - acc: 0.0153 - top_k_categorical_accuracy: 0.0727 - val_loss: 4.5870 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.0781\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.55452\n",
      "Epoch 4/1000\n",
      "144/144 [==============================] - 626s 4s/step - loss: 4.5537 - acc: 0.0186 - top_k_categorical_accuracy: 0.0877 - val_loss: 4.5031 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.55452 to 4.50308, saving model to out/checkpoints/1907191034/004-4.503.hdf5\n",
      "Epoch 5/1000\n",
      "144/144 [==============================] - 614s 4s/step - loss: 4.5417 - acc: 0.0192 - top_k_categorical_accuracy: 0.0914 - val_loss: 4.4682 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.0781\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.50308 to 4.46824, saving model to out/checkpoints/1907191034/005-4.468.hdf5\n",
      "Epoch 6/1000\n",
      "144/144 [==============================] - 613s 4s/step - loss: 4.5159 - acc: 0.0191 - top_k_categorical_accuracy: 0.1005 - val_loss: 4.5382 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 4.46824\n",
      "Epoch 7/1000\n",
      "144/144 [==============================] - 604s 4s/step - loss: 4.4932 - acc: 0.0211 - top_k_categorical_accuracy: 0.1015 - val_loss: 4.5047 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.0938\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 4.46824\n",
      "Epoch 8/1000\n",
      "144/144 [==============================] - 601s 4s/step - loss: 4.4711 - acc: 0.0229 - top_k_categorical_accuracy: 0.1039 - val_loss: 4.4357 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.0938\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.46824 to 4.43572, saving model to out/checkpoints/1907191034/008-4.436.hdf5\n",
      "Epoch 9/1000\n",
      "144/144 [==============================] - 606s 4s/step - loss: 4.4526 - acc: 0.0239 - top_k_categorical_accuracy: 0.1032 - val_loss: 4.4764 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.0938\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 4.43572\n",
      "Epoch 10/1000\n",
      "144/144 [==============================] - 451s 3s/step - loss: 4.4337 - acc: 0.0228 - top_k_categorical_accuracy: 0.1111 - val_loss: 4.4208 - val_acc: 0.0000e+00 - val_top_k_categorical_accuracy: 0.0938\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.43572 to 4.42084, saving model to out/checkpoints/1907191034/010-4.421.hdf5\n",
      "Epoch 11/1000\n",
      "144/144 [==============================] - 436s 3s/step - loss: 4.4313 - acc: 0.0206 - top_k_categorical_accuracy: 0.1022 - val_loss: 4.3860 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.1406\n",
      "\n",
      "Epoch 00011: val_loss improved from 4.42084 to 4.38601, saving model to out/checkpoints/1907191034/011-4.386.hdf5\n",
      "Epoch 12/1000\n",
      "144/144 [==============================] - 433s 3s/step - loss: 4.4202 - acc: 0.0219 - top_k_categorical_accuracy: 0.1020 - val_loss: 4.3697 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.1562\n",
      "\n",
      "Epoch 00012: val_loss improved from 4.38601 to 4.36974, saving model to out/checkpoints/1907191034/012-4.370.hdf5\n",
      "Epoch 13/1000\n",
      "144/144 [==============================] - 428s 3s/step - loss: 4.3979 - acc: 0.0265 - top_k_categorical_accuracy: 0.1097 - val_loss: 4.4619 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.0469\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.36974\n",
      "Epoch 14/1000\n",
      "144/144 [==============================] - 419s 3s/step - loss: 4.3957 - acc: 0.0228 - top_k_categorical_accuracy: 0.1067 - val_loss: 4.4242 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.1562\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 4.36974\n",
      "Epoch 15/1000\n",
      "144/144 [==============================] - 417s 3s/step - loss: 4.3797 - acc: 0.0239 - top_k_categorical_accuracy: 0.1075 - val_loss: 4.2811 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00015: val_loss improved from 4.36974 to 4.28111, saving model to out/checkpoints/1907191034/015-4.281.hdf5\n",
      "Epoch 16/1000\n",
      "144/144 [==============================] - 420s 3s/step - loss: 4.3703 - acc: 0.0263 - top_k_categorical_accuracy: 0.1166 - val_loss: 4.3264 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.1406\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 4.28111\n",
      "Epoch 17/1000\n",
      "144/144 [==============================] - 409s 3s/step - loss: 4.3614 - acc: 0.0231 - top_k_categorical_accuracy: 0.1107 - val_loss: 4.3097 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.1719\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 4.28111\n",
      "Epoch 18/1000\n",
      "144/144 [==============================] - 402s 3s/step - loss: 4.3530 - acc: 0.0242 - top_k_categorical_accuracy: 0.1198 - val_loss: 4.3276 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.1875\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 4.28111\n",
      "Epoch 19/1000\n",
      "144/144 [==============================] - 401s 3s/step - loss: 4.3402 - acc: 0.0246 - top_k_categorical_accuracy: 0.1131 - val_loss: 4.2936 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.28111\n",
      "Epoch 20/1000\n",
      "144/144 [==============================] - 396s 3s/step - loss: 4.3315 - acc: 0.0256 - top_k_categorical_accuracy: 0.1194 - val_loss: 4.3323 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 4.28111\n",
      "Epoch 21/1000\n",
      "144/144 [==============================] - 389s 3s/step - loss: 4.3277 - acc: 0.0269 - top_k_categorical_accuracy: 0.1241 - val_loss: 4.2326 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.2031\n",
      "\n",
      "Epoch 00021: val_loss improved from 4.28111 to 4.23259, saving model to out/checkpoints/1907191034/021-4.233.hdf5\n",
      "Epoch 22/1000\n",
      "144/144 [==============================] - 395s 3s/step - loss: 4.3312 - acc: 0.0267 - top_k_categorical_accuracy: 0.1213 - val_loss: 4.3665 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.1094\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.23259\n",
      "Epoch 23/1000\n",
      "144/144 [==============================] - 382s 3s/step - loss: 4.3237 - acc: 0.0278 - top_k_categorical_accuracy: 0.1263 - val_loss: 4.3905 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.1406\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 4.23259\n",
      "Epoch 24/1000\n",
      "144/144 [==============================] - 381s 3s/step - loss: 4.3252 - acc: 0.0303 - top_k_categorical_accuracy: 0.1319 - val_loss: 4.3048 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.1094\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.23259\n",
      "Epoch 25/1000\n",
      "144/144 [==============================] - 379s 3s/step - loss: 4.2887 - acc: 0.0303 - top_k_categorical_accuracy: 0.1385 - val_loss: 4.1303 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.2031\n",
      "\n",
      "Epoch 00025: val_loss improved from 4.23259 to 4.13027, saving model to out/checkpoints/1907191034/025-4.130.hdf5\n",
      "Epoch 26/1000\n",
      "144/144 [==============================] - 380s 3s/step - loss: 4.2984 - acc: 0.0316 - top_k_categorical_accuracy: 0.1396 - val_loss: 4.2514 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.1406\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 4.13027\n",
      "Epoch 27/1000\n",
      "144/144 [==============================] - 374s 3s/step - loss: 4.2730 - acc: 0.0297 - top_k_categorical_accuracy: 0.1490 - val_loss: 4.2707 - val_acc: 0.0625 - val_top_k_categorical_accuracy: 0.1562\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 4.13027\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 363s 3s/step - loss: 4.2817 - acc: 0.0316 - top_k_categorical_accuracy: 0.1385 - val_loss: 4.2457 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.0781\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.13027\n",
      "Epoch 29/1000\n",
      "144/144 [==============================] - 364s 3s/step - loss: 4.2667 - acc: 0.0324 - top_k_categorical_accuracy: 0.1449 - val_loss: 4.1325 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.2188\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 4.13027\n",
      "Epoch 30/1000\n",
      "144/144 [==============================] - 360s 2s/step - loss: 4.2593 - acc: 0.0353 - top_k_categorical_accuracy: 0.1488 - val_loss: 4.2637 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.1719\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 4.13027\n",
      "Epoch 31/1000\n",
      "144/144 [==============================] - 357s 2s/step - loss: 4.2395 - acc: 0.0368 - top_k_categorical_accuracy: 0.1580 - val_loss: 4.3129 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.1562\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4.13027\n",
      "Epoch 32/1000\n",
      "144/144 [==============================] - 353s 2s/step - loss: 4.2336 - acc: 0.0372 - top_k_categorical_accuracy: 0.1597 - val_loss: 4.3115 - val_acc: 0.0000e+00 - val_top_k_categorical_accuracy: 0.1875\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4.13027\n",
      "Epoch 33/1000\n",
      "144/144 [==============================] - 348s 2s/step - loss: 4.2144 - acc: 0.0422 - top_k_categorical_accuracy: 0.1633 - val_loss: 4.1019 - val_acc: 0.0938 - val_top_k_categorical_accuracy: 0.2031\n",
      "\n",
      "Epoch 00033: val_loss improved from 4.13027 to 4.10192, saving model to out/checkpoints/1907191034/033-4.102.hdf5\n",
      "Epoch 34/1000\n",
      "144/144 [==============================] - 357s 2s/step - loss: 4.2118 - acc: 0.0410 - top_k_categorical_accuracy: 0.1695 - val_loss: 4.1188 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.2188\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4.10192\n",
      "Epoch 35/1000\n",
      "144/144 [==============================] - 348s 2s/step - loss: 4.1988 - acc: 0.0446 - top_k_categorical_accuracy: 0.1742 - val_loss: 4.0232 - val_acc: 0.0625 - val_top_k_categorical_accuracy: 0.2656\n",
      "\n",
      "Epoch 00035: val_loss improved from 4.10192 to 4.02316, saving model to out/checkpoints/1907191034/035-4.023.hdf5\n",
      "Epoch 36/1000\n",
      "144/144 [==============================] - 360s 3s/step - loss: 4.1901 - acc: 0.0446 - top_k_categorical_accuracy: 0.1729 - val_loss: 4.0614 - val_acc: 0.0938 - val_top_k_categorical_accuracy: 0.2188\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 4.02316\n",
      "Epoch 37/1000\n",
      "144/144 [==============================] - 341s 2s/step - loss: 4.1734 - acc: 0.0432 - top_k_categorical_accuracy: 0.1834 - val_loss: 3.8688 - val_acc: 0.1094 - val_top_k_categorical_accuracy: 0.3281\n",
      "\n",
      "Epoch 00037: val_loss improved from 4.02316 to 3.86876, saving model to out/checkpoints/1907191034/037-3.869.hdf5\n",
      "Epoch 38/1000\n",
      "144/144 [==============================] - 350s 2s/step - loss: 4.1642 - acc: 0.0482 - top_k_categorical_accuracy: 0.1866 - val_loss: 4.2166 - val_acc: 0.0312 - val_top_k_categorical_accuracy: 0.1250\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 3.86876\n",
      "Epoch 39/1000\n",
      "144/144 [==============================] - 340s 2s/step - loss: 4.1563 - acc: 0.0442 - top_k_categorical_accuracy: 0.1798 - val_loss: 4.1965 - val_acc: 0.0000e+00 - val_top_k_categorical_accuracy: 0.1562\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.86876\n",
      "Epoch 40/1000\n",
      "144/144 [==============================] - 340s 2s/step - loss: 4.1353 - acc: 0.0498 - top_k_categorical_accuracy: 0.1917 - val_loss: 4.1384 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.2031\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.86876\n",
      "Epoch 41/1000\n",
      "144/144 [==============================] - 341s 2s/step - loss: 4.1281 - acc: 0.0512 - top_k_categorical_accuracy: 0.1974 - val_loss: 4.0968 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.2188\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.86876\n",
      "Epoch 42/1000\n",
      "144/144 [==============================] - 334s 2s/step - loss: 4.1160 - acc: 0.0516 - top_k_categorical_accuracy: 0.1940 - val_loss: 4.2437 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.1562\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 3.86876\n",
      "Epoch 43/1000\n",
      "144/144 [==============================] - 328s 2s/step - loss: 4.1011 - acc: 0.0540 - top_k_categorical_accuracy: 0.2003 - val_loss: 4.0435 - val_acc: 0.0625 - val_top_k_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.86876\n",
      "Epoch 44/1000\n",
      "144/144 [==============================] - 333s 2s/step - loss: 4.0903 - acc: 0.0537 - top_k_categorical_accuracy: 0.2097 - val_loss: 4.0324 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.2656\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 3.86876\n",
      "Epoch 45/1000\n",
      "144/144 [==============================] - 323s 2s/step - loss: 4.0869 - acc: 0.0539 - top_k_categorical_accuracy: 0.2079 - val_loss: 3.9483 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.3438\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.86876\n",
      "Epoch 46/1000\n",
      "144/144 [==============================] - 320s 2s/step - loss: 4.0687 - acc: 0.0549 - top_k_categorical_accuracy: 0.2164 - val_loss: 4.2015 - val_acc: 0.0156 - val_top_k_categorical_accuracy: 0.1406\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.86876\n",
      "Epoch 47/1000\n",
      "144/144 [==============================] - 318s 2s/step - loss: 4.0597 - acc: 0.0551 - top_k_categorical_accuracy: 0.2164 - val_loss: 4.1065 - val_acc: 0.0938 - val_top_k_categorical_accuracy: 0.1875\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.86876\n",
      "Epoch 48/1000\n",
      "144/144 [==============================] - 319s 2s/step - loss: 4.0546 - acc: 0.0540 - top_k_categorical_accuracy: 0.2171 - val_loss: 3.9950 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.3438\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.86876\n",
      "Epoch 49/1000\n",
      "144/144 [==============================] - 315s 2s/step - loss: 4.0401 - acc: 0.0641 - top_k_categorical_accuracy: 0.2323 - val_loss: 4.0772 - val_acc: 0.1250 - val_top_k_categorical_accuracy: 0.3281\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.86876\n",
      "Epoch 50/1000\n",
      "144/144 [==============================] - 316s 2s/step - loss: 4.0218 - acc: 0.0609 - top_k_categorical_accuracy: 0.2360 - val_loss: 4.0142 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.2188\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 3.86876\n",
      "Epoch 51/1000\n",
      "144/144 [==============================] - 313s 2s/step - loss: 4.0224 - acc: 0.0620 - top_k_categorical_accuracy: 0.2335 - val_loss: 4.0015 - val_acc: 0.1250 - val_top_k_categorical_accuracy: 0.3281\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 3.86876\n",
      "Epoch 52/1000\n",
      "144/144 [==============================] - 307s 2s/step - loss: 3.9977 - acc: 0.0628 - top_k_categorical_accuracy: 0.2409 - val_loss: 3.9027 - val_acc: 0.0625 - val_top_k_categorical_accuracy: 0.2812\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.86876\n",
      "Epoch 53/1000\n",
      "144/144 [==============================] - 310s 2s/step - loss: 4.0074 - acc: 0.0649 - top_k_categorical_accuracy: 0.2422 - val_loss: 3.9808 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.2969\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.86876\n",
      "Epoch 54/1000\n",
      "144/144 [==============================] - 309s 2s/step - loss: 3.9697 - acc: 0.0669 - top_k_categorical_accuracy: 0.2548 - val_loss: 3.8915 - val_acc: 0.1250 - val_top_k_categorical_accuracy: 0.3281\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 3.86876\n",
      "Epoch 55/1000\n",
      "144/144 [==============================] - 300s 2s/step - loss: 3.9624 - acc: 0.0683 - top_k_categorical_accuracy: 0.2517 - val_loss: 3.8320 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.3438\n",
      "\n",
      "Epoch 00055: val_loss improved from 3.86876 to 3.83201, saving model to out/checkpoints/1907191034/055-3.832.hdf5\n",
      "Epoch 56/1000\n",
      "144/144 [==============================] - 303s 2s/step - loss: 3.9370 - acc: 0.0726 - top_k_categorical_accuracy: 0.2607 - val_loss: 4.0610 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.2500\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 3.83201\n",
      "Epoch 57/1000\n",
      "144/144 [==============================] - 300s 2s/step - loss: 3.9569 - acc: 0.0652 - top_k_categorical_accuracy: 0.2573 - val_loss: 3.7458 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.3438\n",
      "\n",
      "Epoch 00057: val_loss improved from 3.83201 to 3.74580, saving model to out/checkpoints/1907191034/057-3.746.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "144/144 [==============================] - 301s 2s/step - loss: 3.8992 - acc: 0.0761 - top_k_categorical_accuracy: 0.2694 - val_loss: 3.7476 - val_acc: 0.1562 - val_top_k_categorical_accuracy: 0.2969\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 3.74580\n",
      "Epoch 59/1000\n",
      "144/144 [==============================] - 299s 2s/step - loss: 3.9142 - acc: 0.0748 - top_k_categorical_accuracy: 0.2713 - val_loss: 3.7974 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.3438\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.74580\n",
      "Epoch 60/1000\n",
      "144/144 [==============================] - 291s 2s/step - loss: 3.9098 - acc: 0.0730 - top_k_categorical_accuracy: 0.2686 - val_loss: 3.8788 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 3.74580\n",
      "Epoch 61/1000\n",
      "144/144 [==============================] - 297s 2s/step - loss: 3.8646 - acc: 0.0838 - top_k_categorical_accuracy: 0.2831 - val_loss: 3.6695 - val_acc: 0.1250 - val_top_k_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00061: val_loss improved from 3.74580 to 3.66947, saving model to out/checkpoints/1907191034/061-3.669.hdf5\n",
      "Epoch 62/1000\n",
      "144/144 [==============================] - 294s 2s/step - loss: 3.8804 - acc: 0.0741 - top_k_categorical_accuracy: 0.2789 - val_loss: 4.0898 - val_acc: 0.0625 - val_top_k_categorical_accuracy: 0.1406\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 3.66947\n",
      "Epoch 63/1000\n",
      "144/144 [==============================] - 288s 2s/step - loss: 3.8622 - acc: 0.0828 - top_k_categorical_accuracy: 0.2809 - val_loss: 3.7754 - val_acc: 0.1094 - val_top_k_categorical_accuracy: 0.3281\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 3.66947\n",
      "Epoch 64/1000\n",
      "144/144 [==============================] - 293s 2s/step - loss: 3.8638 - acc: 0.0843 - top_k_categorical_accuracy: 0.2943 - val_loss: 3.6624 - val_acc: 0.0938 - val_top_k_categorical_accuracy: 0.2812\n",
      "\n",
      "Epoch 00064: val_loss improved from 3.66947 to 3.66241, saving model to out/checkpoints/1907191034/064-3.662.hdf5\n",
      "Epoch 65/1000\n",
      "144/144 [==============================] - 290s 2s/step - loss: 3.8310 - acc: 0.0843 - top_k_categorical_accuracy: 0.2949 - val_loss: 3.7163 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.3594\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.66241\n",
      "Epoch 66/1000\n",
      "144/144 [==============================] - 289s 2s/step - loss: 3.8435 - acc: 0.0825 - top_k_categorical_accuracy: 0.2871 - val_loss: 3.7130 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.3281\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.66241\n",
      "Epoch 67/1000\n",
      "144/144 [==============================] - 287s 2s/step - loss: 3.8198 - acc: 0.0879 - top_k_categorical_accuracy: 0.2984 - val_loss: 3.6529 - val_acc: 0.1094 - val_top_k_categorical_accuracy: 0.3906\n",
      "\n",
      "Epoch 00067: val_loss improved from 3.66241 to 3.65293, saving model to out/checkpoints/1907191034/067-3.653.hdf5\n",
      "Epoch 68/1000\n",
      "144/144 [==============================] - 288s 2s/step - loss: 3.8339 - acc: 0.0854 - top_k_categorical_accuracy: 0.2942 - val_loss: 3.8589 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.65293\n",
      "Epoch 69/1000\n",
      "144/144 [==============================] - 283s 2s/step - loss: 3.8019 - acc: 0.0864 - top_k_categorical_accuracy: 0.3072 - val_loss: 3.9399 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.3594\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 3.65293\n",
      "Epoch 70/1000\n",
      "144/144 [==============================] - 287s 2s/step - loss: 3.8110 - acc: 0.0862 - top_k_categorical_accuracy: 0.3033 - val_loss: 4.0598 - val_acc: 0.0469 - val_top_k_categorical_accuracy: 0.3281\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3.65293\n",
      "Epoch 71/1000\n",
      "144/144 [==============================] - 284s 2s/step - loss: 3.7818 - acc: 0.0910 - top_k_categorical_accuracy: 0.3129 - val_loss: 3.3294 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00071: val_loss improved from 3.65293 to 3.32935, saving model to out/checkpoints/1907191034/071-3.329.hdf5\n",
      "Epoch 72/1000\n",
      "144/144 [==============================] - 286s 2s/step - loss: 3.7463 - acc: 0.0939 - top_k_categorical_accuracy: 0.3204 - val_loss: 3.6390 - val_acc: 0.0938 - val_top_k_categorical_accuracy: 0.3906\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 3.32935\n",
      "Epoch 73/1000\n",
      "144/144 [==============================] - 283s 2s/step - loss: 3.7700 - acc: 0.0943 - top_k_categorical_accuracy: 0.3190 - val_loss: 3.7635 - val_acc: 0.1094 - val_top_k_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 3.32935\n",
      "Epoch 74/1000\n",
      "144/144 [==============================] - 277s 2s/step - loss: 3.7570 - acc: 0.0982 - top_k_categorical_accuracy: 0.3162 - val_loss: 3.4097 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.32935\n",
      "Epoch 75/1000\n",
      "144/144 [==============================] - 282s 2s/step - loss: 3.7373 - acc: 0.0983 - top_k_categorical_accuracy: 0.3258 - val_loss: 3.5078 - val_acc: 0.0938 - val_top_k_categorical_accuracy: 0.3438\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.32935\n",
      "Epoch 76/1000\n",
      "144/144 [==============================] - 281s 2s/step - loss: 3.7490 - acc: 0.0975 - top_k_categorical_accuracy: 0.3205 - val_loss: 3.5142 - val_acc: 0.1250 - val_top_k_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.32935\n",
      "Epoch 77/1000\n",
      "144/144 [==============================] - 276s 2s/step - loss: 3.7351 - acc: 0.0961 - top_k_categorical_accuracy: 0.3280 - val_loss: 3.5731 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.32935\n",
      "Epoch 78/1000\n",
      "144/144 [==============================] - 280s 2s/step - loss: 3.6989 - acc: 0.1008 - top_k_categorical_accuracy: 0.3370 - val_loss: 3.7414 - val_acc: 0.1250 - val_top_k_categorical_accuracy: 0.3438\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 3.32935\n",
      "Epoch 79/1000\n",
      "144/144 [==============================] - 278s 2s/step - loss: 3.7039 - acc: 0.1020 - top_k_categorical_accuracy: 0.3360 - val_loss: 3.4042 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.32935\n",
      "Epoch 80/1000\n",
      "144/144 [==============================] - 276s 2s/step - loss: 3.6733 - acc: 0.1061 - top_k_categorical_accuracy: 0.3452 - val_loss: 3.7802 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.3594\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3.32935\n",
      "Epoch 81/1000\n",
      "144/144 [==============================] - 278s 2s/step - loss: 3.7146 - acc: 0.0985 - top_k_categorical_accuracy: 0.3365 - val_loss: 3.8258 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 3.32935\n",
      "Epoch 82/1000\n",
      "144/144 [==============================] - 277s 2s/step - loss: 3.6965 - acc: 0.1024 - top_k_categorical_accuracy: 0.3366 - val_loss: 3.1798 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00082: val_loss improved from 3.32935 to 3.17983, saving model to out/checkpoints/1907191034/082-3.180.hdf5\n",
      "Epoch 83/1000\n",
      "144/144 [==============================] - 278s 2s/step - loss: 3.6753 - acc: 0.1034 - top_k_categorical_accuracy: 0.3333 - val_loss: 3.6447 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 3.17983\n",
      "Epoch 84/1000\n",
      "144/144 [==============================] - 277s 2s/step - loss: 3.6658 - acc: 0.1058 - top_k_categorical_accuracy: 0.3429 - val_loss: 3.5963 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 3.17983\n",
      "Epoch 85/1000\n",
      "144/144 [==============================] - 276s 2s/step - loss: 3.6901 - acc: 0.1057 - top_k_categorical_accuracy: 0.3420 - val_loss: 3.6492 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.3594\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 3.17983\n",
      "Epoch 86/1000\n",
      "144/144 [==============================] - 273s 2s/step - loss: 3.6373 - acc: 0.1101 - top_k_categorical_accuracy: 0.3506 - val_loss: 3.7476 - val_acc: 0.1094 - val_top_k_categorical_accuracy: 0.3438\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3.17983\n",
      "Epoch 87/1000\n",
      "144/144 [==============================] - 275s 2s/step - loss: 3.6675 - acc: 0.1085 - top_k_categorical_accuracy: 0.3472 - val_loss: 3.6033 - val_acc: 0.1562 - val_top_k_categorical_accuracy: 0.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00087: val_loss did not improve from 3.17983\n",
      "Epoch 88/1000\n",
      "144/144 [==============================] - 277s 2s/step - loss: 3.6460 - acc: 0.1110 - top_k_categorical_accuracy: 0.3582 - val_loss: 3.5829 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.3906\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.17983\n",
      "Epoch 89/1000\n",
      "144/144 [==============================] - 274s 2s/step - loss: 3.6111 - acc: 0.1113 - top_k_categorical_accuracy: 0.3627 - val_loss: 3.4753 - val_acc: 0.1094 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 3.17983\n",
      "Epoch 90/1000\n",
      "144/144 [==============================] - 276s 2s/step - loss: 3.6140 - acc: 0.1121 - top_k_categorical_accuracy: 0.3605 - val_loss: 3.3842 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.3906\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 3.17983\n",
      "Epoch 91/1000\n",
      "144/144 [==============================] - 274s 2s/step - loss: 3.6361 - acc: 0.1157 - top_k_categorical_accuracy: 0.3623 - val_loss: 3.4988 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.17983\n",
      "Epoch 92/1000\n",
      "144/144 [==============================] - 277s 2s/step - loss: 3.5958 - acc: 0.1187 - top_k_categorical_accuracy: 0.3702 - val_loss: 3.4514 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 3.17983\n",
      "Epoch 93/1000\n",
      "144/144 [==============================] - 272s 2s/step - loss: 3.5845 - acc: 0.1209 - top_k_categorical_accuracy: 0.3708 - val_loss: 3.5647 - val_acc: 0.0938 - val_top_k_categorical_accuracy: 0.3594\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 3.17983\n",
      "Epoch 94/1000\n",
      "144/144 [==============================] - 272s 2s/step - loss: 3.6278 - acc: 0.1149 - top_k_categorical_accuracy: 0.3617 - val_loss: 3.3880 - val_acc: 0.1562 - val_top_k_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.17983\n",
      "Epoch 95/1000\n",
      "144/144 [==============================] - 271s 2s/step - loss: 3.5757 - acc: 0.1211 - top_k_categorical_accuracy: 0.3719 - val_loss: 3.2792 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.3906\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.17983\n",
      "Epoch 96/1000\n",
      "144/144 [==============================] - 270s 2s/step - loss: 3.5738 - acc: 0.1198 - top_k_categorical_accuracy: 0.3745 - val_loss: 3.5738 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.3906\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 3.17983\n",
      "Epoch 97/1000\n",
      "144/144 [==============================] - 273s 2s/step - loss: 3.5738 - acc: 0.1220 - top_k_categorical_accuracy: 0.3764 - val_loss: 3.3494 - val_acc: 0.1250 - val_top_k_categorical_accuracy: 0.4531\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 3.17983\n",
      "Epoch 98/1000\n",
      "144/144 [==============================] - 272s 2s/step - loss: 3.5789 - acc: 0.1245 - top_k_categorical_accuracy: 0.3726 - val_loss: 3.4065 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 3.17983\n",
      "Epoch 99/1000\n",
      "144/144 [==============================] - 270s 2s/step - loss: 3.5508 - acc: 0.1276 - top_k_categorical_accuracy: 0.3800 - val_loss: 3.4294 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3.17983\n",
      "Epoch 100/1000\n",
      "144/144 [==============================] - 275s 2s/step - loss: 3.5509 - acc: 0.1267 - top_k_categorical_accuracy: 0.3844 - val_loss: 3.3364 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3.17983\n",
      "Epoch 101/1000\n",
      "144/144 [==============================] - 270s 2s/step - loss: 3.5729 - acc: 0.1226 - top_k_categorical_accuracy: 0.3822 - val_loss: 3.5359 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 3.17983\n",
      "Epoch 102/1000\n",
      "144/144 [==============================] - 269s 2s/step - loss: 3.5565 - acc: 0.1296 - top_k_categorical_accuracy: 0.3863 - val_loss: 3.1349 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00102: val_loss improved from 3.17983 to 3.13488, saving model to out/checkpoints/1907191034/102-3.135.hdf5\n",
      "Epoch 103/1000\n",
      "144/144 [==============================] - 271s 2s/step - loss: 3.5332 - acc: 0.1324 - top_k_categorical_accuracy: 0.3891 - val_loss: 3.3995 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 3.13488\n",
      "Epoch 104/1000\n",
      "144/144 [==============================] - 268s 2s/step - loss: 3.5227 - acc: 0.1306 - top_k_categorical_accuracy: 0.3882 - val_loss: 3.2417 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 3.13488\n",
      "Epoch 105/1000\n",
      "144/144 [==============================] - 267s 2s/step - loss: 3.5278 - acc: 0.1337 - top_k_categorical_accuracy: 0.3891 - val_loss: 3.0498 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00105: val_loss improved from 3.13488 to 3.04982, saving model to out/checkpoints/1907191034/105-3.050.hdf5\n",
      "Epoch 106/1000\n",
      "144/144 [==============================] - 270s 2s/step - loss: 3.5414 - acc: 0.1270 - top_k_categorical_accuracy: 0.3913 - val_loss: 3.6514 - val_acc: 0.0781 - val_top_k_categorical_accuracy: 0.3594\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 3.04982\n",
      "Epoch 107/1000\n",
      "144/144 [==============================] - 270s 2s/step - loss: 3.5106 - acc: 0.1324 - top_k_categorical_accuracy: 0.3923 - val_loss: 3.4625 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 3.04982\n",
      "Epoch 108/1000\n",
      "144/144 [==============================] - 267s 2s/step - loss: 3.4891 - acc: 0.1374 - top_k_categorical_accuracy: 0.4089 - val_loss: 3.4140 - val_acc: 0.0625 - val_top_k_categorical_accuracy: 0.3594\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 3.04982\n",
      "Epoch 109/1000\n",
      "144/144 [==============================] - 265s 2s/step - loss: 3.4711 - acc: 0.1366 - top_k_categorical_accuracy: 0.4005 - val_loss: 3.4043 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 3.04982\n",
      "Epoch 110/1000\n",
      "144/144 [==============================] - 268s 2s/step - loss: 3.4894 - acc: 0.1365 - top_k_categorical_accuracy: 0.4038 - val_loss: 3.4479 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 3.04982\n",
      "Epoch 111/1000\n",
      "144/144 [==============================] - 268s 2s/step - loss: 3.4800 - acc: 0.1434 - top_k_categorical_accuracy: 0.4043 - val_loss: 3.2463 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 3.04982\n",
      "Epoch 112/1000\n",
      "144/144 [==============================] - 263s 2s/step - loss: 3.5275 - acc: 0.1380 - top_k_categorical_accuracy: 0.3958 - val_loss: 3.2494 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.4531\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 3.04982\n",
      "Epoch 113/1000\n",
      "144/144 [==============================] - 265s 2s/step - loss: 3.4605 - acc: 0.1447 - top_k_categorical_accuracy: 0.4238 - val_loss: 3.4157 - val_acc: 0.1562 - val_top_k_categorical_accuracy: 0.4531\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 3.04982\n",
      "Epoch 114/1000\n",
      "144/144 [==============================] - 268s 2s/step - loss: 3.4691 - acc: 0.1428 - top_k_categorical_accuracy: 0.4144 - val_loss: 3.1223 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 3.04982\n",
      "Epoch 115/1000\n",
      "144/144 [==============================] - 265s 2s/step - loss: 3.4878 - acc: 0.1421 - top_k_categorical_accuracy: 0.4097 - val_loss: 3.3703 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 3.04982\n",
      "Epoch 116/1000\n",
      "144/144 [==============================] - 268s 2s/step - loss: 3.4743 - acc: 0.1437 - top_k_categorical_accuracy: 0.4105 - val_loss: 3.3139 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.4531\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 3.04982\n",
      "Epoch 117/1000\n",
      "144/144 [==============================] - 260s 2s/step - loss: 3.4272 - acc: 0.1481 - top_k_categorical_accuracy: 0.4194 - val_loss: 3.2807 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 3.04982\n",
      "Epoch 118/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 263s 2s/step - loss: 3.4702 - acc: 0.1398 - top_k_categorical_accuracy: 0.4118 - val_loss: 3.2561 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4531\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 3.04982\n",
      "Epoch 119/1000\n",
      "144/144 [==============================] - 261s 2s/step - loss: 3.4514 - acc: 0.1419 - top_k_categorical_accuracy: 0.4206 - val_loss: 3.4666 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 3.04982\n",
      "Epoch 120/1000\n",
      "144/144 [==============================] - 262s 2s/step - loss: 3.4387 - acc: 0.1444 - top_k_categorical_accuracy: 0.4200 - val_loss: 3.4503 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.4531\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 3.04982\n",
      "Epoch 121/1000\n",
      "144/144 [==============================] - 261s 2s/step - loss: 3.4317 - acc: 0.1525 - top_k_categorical_accuracy: 0.4227 - val_loss: 3.4352 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 3.04982\n",
      "Epoch 122/1000\n",
      "144/144 [==============================] - 262s 2s/step - loss: 3.4112 - acc: 0.1578 - top_k_categorical_accuracy: 0.4325 - val_loss: 3.3874 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 3.04982\n",
      "Epoch 123/1000\n",
      "144/144 [==============================] - 263s 2s/step - loss: 3.4261 - acc: 0.1502 - top_k_categorical_accuracy: 0.4224 - val_loss: 3.2467 - val_acc: 0.1562 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 3.04982\n",
      "Epoch 124/1000\n",
      "144/144 [==============================] - 265s 2s/step - loss: 3.4015 - acc: 0.1557 - top_k_categorical_accuracy: 0.4392 - val_loss: 3.3961 - val_acc: 0.0938 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 3.04982\n",
      "Epoch 125/1000\n",
      "144/144 [==============================] - 264s 2s/step - loss: 3.4057 - acc: 0.1528 - top_k_categorical_accuracy: 0.4321 - val_loss: 3.0649 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 3.04982\n",
      "Epoch 126/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.3959 - acc: 0.1590 - top_k_categorical_accuracy: 0.4329 - val_loss: 3.2272 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 3.04982\n",
      "Epoch 127/1000\n",
      "144/144 [==============================] - 261s 2s/step - loss: 3.4101 - acc: 0.1589 - top_k_categorical_accuracy: 0.4333 - val_loss: 3.4426 - val_acc: 0.1094 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 3.04982\n",
      "Epoch 128/1000\n",
      "144/144 [==============================] - 265s 2s/step - loss: 3.4102 - acc: 0.1544 - top_k_categorical_accuracy: 0.4276 - val_loss: 3.5154 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.3750\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 3.04982\n",
      "Epoch 129/1000\n",
      "144/144 [==============================] - 263s 2s/step - loss: 3.3920 - acc: 0.1536 - top_k_categorical_accuracy: 0.4348 - val_loss: 3.2716 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 3.04982\n",
      "Epoch 130/1000\n",
      "144/144 [==============================] - 263s 2s/step - loss: 3.4054 - acc: 0.1532 - top_k_categorical_accuracy: 0.4337 - val_loss: 3.3273 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 3.04982\n",
      "Epoch 131/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.4167 - acc: 0.1561 - top_k_categorical_accuracy: 0.4338 - val_loss: 3.2787 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 3.04982\n",
      "Epoch 132/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.3899 - acc: 0.1615 - top_k_categorical_accuracy: 0.4311 - val_loss: 3.3990 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 3.04982\n",
      "Epoch 133/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.3749 - acc: 0.1581 - top_k_categorical_accuracy: 0.4450 - val_loss: 3.1825 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 3.04982\n",
      "Epoch 134/1000\n",
      "144/144 [==============================] - 262s 2s/step - loss: 3.3631 - acc: 0.1683 - top_k_categorical_accuracy: 0.4487 - val_loss: 3.3249 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.4531\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 3.04982\n",
      "Epoch 135/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.3955 - acc: 0.1582 - top_k_categorical_accuracy: 0.4358 - val_loss: 3.3515 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 3.04982\n",
      "Epoch 136/1000\n",
      "144/144 [==============================] - 261s 2s/step - loss: 3.3465 - acc: 0.1721 - top_k_categorical_accuracy: 0.4495 - val_loss: 3.2070 - val_acc: 0.1562 - val_top_k_categorical_accuracy: 0.4219\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 3.04982\n",
      "Epoch 137/1000\n",
      "144/144 [==============================] - 262s 2s/step - loss: 3.3242 - acc: 0.1747 - top_k_categorical_accuracy: 0.4540 - val_loss: 3.1291 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 3.04982\n",
      "Epoch 138/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.3001 - acc: 0.1764 - top_k_categorical_accuracy: 0.4625 - val_loss: 3.0916 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 3.04982\n",
      "Epoch 139/1000\n",
      "144/144 [==============================] - 261s 2s/step - loss: 3.3309 - acc: 0.1670 - top_k_categorical_accuracy: 0.4638 - val_loss: 2.9060 - val_acc: 0.4375 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00139: val_loss improved from 3.04982 to 2.90603, saving model to out/checkpoints/1907191034/139-2.906.hdf5\n",
      "Epoch 140/1000\n",
      "144/144 [==============================] - 262s 2s/step - loss: 3.3418 - acc: 0.1771 - top_k_categorical_accuracy: 0.4543 - val_loss: 3.1811 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 2.90603\n",
      "Epoch 141/1000\n",
      "144/144 [==============================] - 262s 2s/step - loss: 3.3017 - acc: 0.1753 - top_k_categorical_accuracy: 0.4629 - val_loss: 3.0863 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 2.90603\n",
      "Epoch 142/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.3192 - acc: 0.1810 - top_k_categorical_accuracy: 0.4593 - val_loss: 2.8211 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00142: val_loss improved from 2.90603 to 2.82109, saving model to out/checkpoints/1907191034/142-2.821.hdf5\n",
      "Epoch 143/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.3379 - acc: 0.1680 - top_k_categorical_accuracy: 0.4583 - val_loss: 3.1540 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 2.82109\n",
      "Epoch 144/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.3302 - acc: 0.1755 - top_k_categorical_accuracy: 0.4626 - val_loss: 3.2143 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 2.82109\n",
      "Epoch 145/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.3165 - acc: 0.1750 - top_k_categorical_accuracy: 0.4501 - val_loss: 3.4238 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 2.82109\n",
      "Epoch 146/1000\n",
      "144/144 [==============================] - 260s 2s/step - loss: 3.3117 - acc: 0.1768 - top_k_categorical_accuracy: 0.4584 - val_loss: 2.9136 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 2.82109\n",
      "Epoch 147/1000\n",
      "144/144 [==============================] - 260s 2s/step - loss: 3.2922 - acc: 0.1811 - top_k_categorical_accuracy: 0.4697 - val_loss: 3.1728 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 2.82109\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 258s 2s/step - loss: 3.3118 - acc: 0.1738 - top_k_categorical_accuracy: 0.4619 - val_loss: 3.0587 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 2.82109\n",
      "Epoch 149/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.2899 - acc: 0.1825 - top_k_categorical_accuracy: 0.4705 - val_loss: 3.0130 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 2.82109\n",
      "Epoch 150/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.2885 - acc: 0.1821 - top_k_categorical_accuracy: 0.4752 - val_loss: 3.2233 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 2.82109\n",
      "Epoch 151/1000\n",
      "144/144 [==============================] - 260s 2s/step - loss: 3.2819 - acc: 0.1783 - top_k_categorical_accuracy: 0.4721 - val_loss: 3.1681 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 2.82109\n",
      "Epoch 152/1000\n",
      "144/144 [==============================] - 262s 2s/step - loss: 3.2962 - acc: 0.1821 - top_k_categorical_accuracy: 0.4646 - val_loss: 2.9247 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 2.82109\n",
      "Epoch 153/1000\n",
      "144/144 [==============================] - 261s 2s/step - loss: 3.2511 - acc: 0.1933 - top_k_categorical_accuracy: 0.4847 - val_loss: 3.1565 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 2.82109\n",
      "Epoch 154/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.2920 - acc: 0.1855 - top_k_categorical_accuracy: 0.4688 - val_loss: 3.0605 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 2.82109\n",
      "Epoch 155/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.2571 - acc: 0.1867 - top_k_categorical_accuracy: 0.4822 - val_loss: 3.0315 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 2.82109\n",
      "Epoch 156/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.2585 - acc: 0.1873 - top_k_categorical_accuracy: 0.4760 - val_loss: 3.0338 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 2.82109\n",
      "Epoch 157/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.2370 - acc: 0.1949 - top_k_categorical_accuracy: 0.4812 - val_loss: 2.9746 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 2.82109\n",
      "Epoch 158/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.2637 - acc: 0.1820 - top_k_categorical_accuracy: 0.4719 - val_loss: 3.1795 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 2.82109\n",
      "Epoch 159/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.2508 - acc: 0.1903 - top_k_categorical_accuracy: 0.4830 - val_loss: 3.2093 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 2.82109\n",
      "Epoch 160/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.2558 - acc: 0.1930 - top_k_categorical_accuracy: 0.4789 - val_loss: 3.2291 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 2.82109\n",
      "Epoch 161/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.2343 - acc: 0.1893 - top_k_categorical_accuracy: 0.4757 - val_loss: 3.0565 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 2.82109\n",
      "Epoch 162/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.2305 - acc: 0.1934 - top_k_categorical_accuracy: 0.4878 - val_loss: 3.2131 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 2.82109\n",
      "Epoch 163/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.2372 - acc: 0.1950 - top_k_categorical_accuracy: 0.4863 - val_loss: 3.0569 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 2.82109\n",
      "Epoch 164/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.2447 - acc: 0.1865 - top_k_categorical_accuracy: 0.4763 - val_loss: 3.0082 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 2.82109\n",
      "Epoch 165/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.2244 - acc: 0.1940 - top_k_categorical_accuracy: 0.4923 - val_loss: 2.9727 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 2.82109\n",
      "Epoch 166/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.2406 - acc: 0.1986 - top_k_categorical_accuracy: 0.4842 - val_loss: 3.0875 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 2.82109\n",
      "Epoch 167/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.2449 - acc: 0.1908 - top_k_categorical_accuracy: 0.4806 - val_loss: 2.9745 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 2.82109\n",
      "Epoch 168/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.2545 - acc: 0.1922 - top_k_categorical_accuracy: 0.4806 - val_loss: 2.9832 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 2.82109\n",
      "Epoch 169/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.2143 - acc: 0.1921 - top_k_categorical_accuracy: 0.4920 - val_loss: 3.2514 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 2.82109\n",
      "Epoch 170/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.2088 - acc: 0.2005 - top_k_categorical_accuracy: 0.4898 - val_loss: 3.3250 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 2.82109\n",
      "Epoch 171/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.1987 - acc: 0.2015 - top_k_categorical_accuracy: 0.4947 - val_loss: 3.0789 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 2.82109\n",
      "Epoch 172/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.2168 - acc: 0.1970 - top_k_categorical_accuracy: 0.4947 - val_loss: 3.2129 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 2.82109\n",
      "Epoch 173/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1833 - acc: 0.2077 - top_k_categorical_accuracy: 0.4976 - val_loss: 3.1366 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 2.82109\n",
      "Epoch 174/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1973 - acc: 0.2024 - top_k_categorical_accuracy: 0.4961 - val_loss: 3.0720 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 2.82109\n",
      "Epoch 175/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1907 - acc: 0.2067 - top_k_categorical_accuracy: 0.4948 - val_loss: 2.9055 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 2.82109\n",
      "Epoch 176/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.1656 - acc: 0.2143 - top_k_categorical_accuracy: 0.5016 - val_loss: 2.8317 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 2.82109\n",
      "Epoch 177/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.1663 - acc: 0.2150 - top_k_categorical_accuracy: 0.5048 - val_loss: 2.9870 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 2.82109\n",
      "Epoch 178/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.1559 - acc: 0.2107 - top_k_categorical_accuracy: 0.5073 - val_loss: 3.1366 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00178: val_loss did not improve from 2.82109\n",
      "Epoch 179/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.1667 - acc: 0.2080 - top_k_categorical_accuracy: 0.5063 - val_loss: 3.1230 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 2.82109\n",
      "Epoch 180/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.1659 - acc: 0.2048 - top_k_categorical_accuracy: 0.5021 - val_loss: 2.9495 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 2.82109\n",
      "Epoch 181/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.1763 - acc: 0.2083 - top_k_categorical_accuracy: 0.5068 - val_loss: 3.0125 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 2.82109\n",
      "Epoch 182/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1786 - acc: 0.2117 - top_k_categorical_accuracy: 0.4990 - val_loss: 3.1091 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 2.82109\n",
      "Epoch 183/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.1471 - acc: 0.2127 - top_k_categorical_accuracy: 0.5180 - val_loss: 2.9770 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 2.82109\n",
      "Epoch 184/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.1683 - acc: 0.2128 - top_k_categorical_accuracy: 0.5080 - val_loss: 3.0367 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 2.82109\n",
      "Epoch 185/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.1576 - acc: 0.2140 - top_k_categorical_accuracy: 0.5063 - val_loss: 3.3053 - val_acc: 0.1562 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 2.82109\n",
      "Epoch 186/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.1453 - acc: 0.2132 - top_k_categorical_accuracy: 0.5034 - val_loss: 2.9787 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 2.82109\n",
      "Epoch 187/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.1329 - acc: 0.2179 - top_k_categorical_accuracy: 0.5110 - val_loss: 3.1310 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 2.82109\n",
      "Epoch 188/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.1438 - acc: 0.2188 - top_k_categorical_accuracy: 0.5119 - val_loss: 3.0309 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 2.82109\n",
      "Epoch 189/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.1484 - acc: 0.2195 - top_k_categorical_accuracy: 0.5128 - val_loss: 3.4522 - val_acc: 0.1406 - val_top_k_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 2.82109\n",
      "Epoch 190/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.1578 - acc: 0.2084 - top_k_categorical_accuracy: 0.5037 - val_loss: 3.0561 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 2.82109\n",
      "Epoch 191/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.1651 - acc: 0.2079 - top_k_categorical_accuracy: 0.4959 - val_loss: 2.8913 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 2.82109\n",
      "Epoch 192/1000\n",
      "144/144 [==============================] - 259s 2s/step - loss: 3.1401 - acc: 0.2147 - top_k_categorical_accuracy: 0.5065 - val_loss: 2.8208 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00192: val_loss improved from 2.82109 to 2.82076, saving model to out/checkpoints/1907191034/192-2.821.hdf5\n",
      "Epoch 193/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.1397 - acc: 0.2118 - top_k_categorical_accuracy: 0.5136 - val_loss: 2.9672 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 2.82076\n",
      "Epoch 194/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0991 - acc: 0.2307 - top_k_categorical_accuracy: 0.5171 - val_loss: 2.9890 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 2.82076\n",
      "Epoch 195/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1438 - acc: 0.2186 - top_k_categorical_accuracy: 0.5107 - val_loss: 3.2753 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 2.82076\n",
      "Epoch 196/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.1145 - acc: 0.2229 - top_k_categorical_accuracy: 0.5169 - val_loss: 3.2050 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 2.82076\n",
      "Epoch 197/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1203 - acc: 0.2218 - top_k_categorical_accuracy: 0.5170 - val_loss: 2.7798 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00197: val_loss improved from 2.82076 to 2.77980, saving model to out/checkpoints/1907191034/197-2.780.hdf5\n",
      "Epoch 198/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.0960 - acc: 0.2205 - top_k_categorical_accuracy: 0.5244 - val_loss: 2.9085 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 2.77980\n",
      "Epoch 199/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.1053 - acc: 0.2223 - top_k_categorical_accuracy: 0.5206 - val_loss: 2.7971 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 2.77980\n",
      "Epoch 200/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1259 - acc: 0.2209 - top_k_categorical_accuracy: 0.5136 - val_loss: 2.9926 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 2.77980\n",
      "Epoch 201/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.1033 - acc: 0.2216 - top_k_categorical_accuracy: 0.5245 - val_loss: 3.0305 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 2.77980\n",
      "Epoch 202/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.0984 - acc: 0.2283 - top_k_categorical_accuracy: 0.5288 - val_loss: 2.8320 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 2.77980\n",
      "Epoch 203/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1060 - acc: 0.2244 - top_k_categorical_accuracy: 0.5224 - val_loss: 2.8902 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 2.77980\n",
      "Epoch 204/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.0938 - acc: 0.2318 - top_k_categorical_accuracy: 0.5322 - val_loss: 3.0763 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 2.77980\n",
      "Epoch 205/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0928 - acc: 0.2202 - top_k_categorical_accuracy: 0.5244 - val_loss: 2.9507 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 2.77980\n",
      "Epoch 206/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.1093 - acc: 0.2292 - top_k_categorical_accuracy: 0.5216 - val_loss: 2.9249 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 2.77980\n",
      "Epoch 207/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1144 - acc: 0.2207 - top_k_categorical_accuracy: 0.5201 - val_loss: 3.1972 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 2.77980\n",
      "Epoch 208/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.1039 - acc: 0.2238 - top_k_categorical_accuracy: 0.5239 - val_loss: 2.8087 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 2.77980\n",
      "Epoch 209/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 254s 2s/step - loss: 3.0974 - acc: 0.2274 - top_k_categorical_accuracy: 0.5312 - val_loss: 2.9567 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 2.77980\n",
      "Epoch 210/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.1300 - acc: 0.2300 - top_k_categorical_accuracy: 0.5154 - val_loss: 2.7384 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00210: val_loss improved from 2.77980 to 2.73839, saving model to out/checkpoints/1907191034/210-2.738.hdf5\n",
      "Epoch 211/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.1056 - acc: 0.2316 - top_k_categorical_accuracy: 0.5183 - val_loss: 2.7884 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 2.73839\n",
      "Epoch 212/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0902 - acc: 0.2316 - top_k_categorical_accuracy: 0.5211 - val_loss: 2.8612 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 2.73839\n",
      "Epoch 213/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 3.0701 - acc: 0.2319 - top_k_categorical_accuracy: 0.5369 - val_loss: 2.9318 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 2.73839\n",
      "Epoch 214/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.1015 - acc: 0.2257 - top_k_categorical_accuracy: 0.5246 - val_loss: 3.2751 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 2.73839\n",
      "Epoch 215/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0800 - acc: 0.2371 - top_k_categorical_accuracy: 0.5293 - val_loss: 2.9886 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 2.73839\n",
      "Epoch 216/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.1260 - acc: 0.2281 - top_k_categorical_accuracy: 0.5179 - val_loss: 2.9652 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 2.73839\n",
      "Epoch 217/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0921 - acc: 0.2319 - top_k_categorical_accuracy: 0.5203 - val_loss: 2.6982 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00217: val_loss improved from 2.73839 to 2.69821, saving model to out/checkpoints/1907191034/217-2.698.hdf5\n",
      "Epoch 218/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0977 - acc: 0.2351 - top_k_categorical_accuracy: 0.5304 - val_loss: 2.7670 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 2.69821\n",
      "Epoch 219/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0804 - acc: 0.2342 - top_k_categorical_accuracy: 0.5292 - val_loss: 3.1234 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 2.69821\n",
      "Epoch 220/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0872 - acc: 0.2330 - top_k_categorical_accuracy: 0.5263 - val_loss: 2.7538 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 2.69821\n",
      "Epoch 221/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0388 - acc: 0.2365 - top_k_categorical_accuracy: 0.5371 - val_loss: 3.3253 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 2.69821\n",
      "Epoch 222/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0641 - acc: 0.2348 - top_k_categorical_accuracy: 0.5324 - val_loss: 3.0790 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 2.69821\n",
      "Epoch 223/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0620 - acc: 0.2378 - top_k_categorical_accuracy: 0.5340 - val_loss: 3.0403 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 2.69821\n",
      "Epoch 224/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0889 - acc: 0.2333 - top_k_categorical_accuracy: 0.5310 - val_loss: 2.7840 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 2.69821\n",
      "Epoch 225/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0703 - acc: 0.2309 - top_k_categorical_accuracy: 0.5365 - val_loss: 2.9634 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 2.69821\n",
      "Epoch 226/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0750 - acc: 0.2318 - top_k_categorical_accuracy: 0.5341 - val_loss: 3.1238 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 2.69821\n",
      "Epoch 227/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0771 - acc: 0.2349 - top_k_categorical_accuracy: 0.5259 - val_loss: 3.0667 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 2.69821\n",
      "Epoch 228/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0983 - acc: 0.2294 - top_k_categorical_accuracy: 0.5286 - val_loss: 2.9857 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 2.69821\n",
      "Epoch 229/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0854 - acc: 0.2263 - top_k_categorical_accuracy: 0.5272 - val_loss: 3.1462 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 2.69821\n",
      "Epoch 230/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0331 - acc: 0.2398 - top_k_categorical_accuracy: 0.5428 - val_loss: 2.9766 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 2.69821\n",
      "Epoch 231/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0404 - acc: 0.2424 - top_k_categorical_accuracy: 0.5370 - val_loss: 2.8494 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 2.69821\n",
      "Epoch 232/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0495 - acc: 0.2427 - top_k_categorical_accuracy: 0.5419 - val_loss: 2.8467 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 2.69821\n",
      "Epoch 233/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0363 - acc: 0.2415 - top_k_categorical_accuracy: 0.5375 - val_loss: 2.8376 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 2.69821\n",
      "Epoch 234/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0654 - acc: 0.2409 - top_k_categorical_accuracy: 0.5330 - val_loss: 2.8469 - val_acc: 0.3906 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 2.69821\n",
      "Epoch 235/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0523 - acc: 0.2361 - top_k_categorical_accuracy: 0.5349 - val_loss: 3.0213 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 2.69821\n",
      "Epoch 236/1000\n",
      "144/144 [==============================] - 248s 2s/step - loss: 3.0479 - acc: 0.2381 - top_k_categorical_accuracy: 0.5362 - val_loss: 2.7475 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 2.69821\n",
      "Epoch 237/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0621 - acc: 0.2432 - top_k_categorical_accuracy: 0.5365 - val_loss: 3.1584 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 2.69821\n",
      "Epoch 238/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0674 - acc: 0.2385 - top_k_categorical_accuracy: 0.5327 - val_loss: 2.7971 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 2.69821\n",
      "Epoch 239/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 250s 2s/step - loss: 3.0177 - acc: 0.2401 - top_k_categorical_accuracy: 0.5458 - val_loss: 3.1775 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 2.69821\n",
      "Epoch 240/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0416 - acc: 0.2422 - top_k_categorical_accuracy: 0.5359 - val_loss: 2.8557 - val_acc: 0.3750 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 2.69821\n",
      "Epoch 241/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0493 - acc: 0.2427 - top_k_categorical_accuracy: 0.5356 - val_loss: 2.7383 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 2.69821\n",
      "Epoch 242/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0109 - acc: 0.2464 - top_k_categorical_accuracy: 0.5450 - val_loss: 2.8642 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 2.69821\n",
      "Epoch 243/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0447 - acc: 0.2441 - top_k_categorical_accuracy: 0.5373 - val_loss: 2.6623 - val_acc: 0.3750 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00243: val_loss improved from 2.69821 to 2.66228, saving model to out/checkpoints/1907191034/243-2.662.hdf5\n",
      "Epoch 244/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0528 - acc: 0.2390 - top_k_categorical_accuracy: 0.5441 - val_loss: 3.0114 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 2.66228\n",
      "Epoch 245/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0118 - acc: 0.2456 - top_k_categorical_accuracy: 0.5445 - val_loss: 2.8568 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 2.66228\n",
      "Epoch 246/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0314 - acc: 0.2439 - top_k_categorical_accuracy: 0.5426 - val_loss: 2.7479 - val_acc: 0.4062 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 2.66228\n",
      "Epoch 247/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0461 - acc: 0.2381 - top_k_categorical_accuracy: 0.5365 - val_loss: 2.6425 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00247: val_loss improved from 2.66228 to 2.64246, saving model to out/checkpoints/1907191034/247-2.642.hdf5\n",
      "Epoch 248/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0354 - acc: 0.2432 - top_k_categorical_accuracy: 0.5390 - val_loss: 2.7221 - val_acc: 0.3906 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 2.64246\n",
      "Epoch 249/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0703 - acc: 0.2438 - top_k_categorical_accuracy: 0.5350 - val_loss: 2.8589 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.7031\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 2.64246\n",
      "Epoch 250/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 2.9978 - acc: 0.2493 - top_k_categorical_accuracy: 0.5470 - val_loss: 2.7618 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.7031\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 2.64246\n",
      "Epoch 251/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0533 - acc: 0.2428 - top_k_categorical_accuracy: 0.5384 - val_loss: 2.7020 - val_acc: 0.3750 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 2.64246\n",
      "Epoch 252/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0314 - acc: 0.2448 - top_k_categorical_accuracy: 0.5438 - val_loss: 2.9898 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 2.64246\n",
      "Epoch 253/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0438 - acc: 0.2382 - top_k_categorical_accuracy: 0.5423 - val_loss: 3.2030 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 2.64246\n",
      "Epoch 254/1000\n",
      "144/144 [==============================] - 249s 2s/step - loss: 3.0005 - acc: 0.2509 - top_k_categorical_accuracy: 0.5475 - val_loss: 2.9023 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 2.64246\n",
      "Epoch 255/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.0453 - acc: 0.2520 - top_k_categorical_accuracy: 0.5372 - val_loss: 2.8932 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 2.64246\n",
      "Epoch 256/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0050 - acc: 0.2452 - top_k_categorical_accuracy: 0.5501 - val_loss: 3.0374 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 2.64246\n",
      "Epoch 257/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0554 - acc: 0.2440 - top_k_categorical_accuracy: 0.5405 - val_loss: 2.7205 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 2.64246\n",
      "Epoch 258/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0253 - acc: 0.2484 - top_k_categorical_accuracy: 0.5473 - val_loss: 2.9024 - val_acc: 0.3594 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 2.64246\n",
      "Epoch 259/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 2.9933 - acc: 0.2477 - top_k_categorical_accuracy: 0.5538 - val_loss: 3.0204 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 2.64246\n",
      "Epoch 260/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0324 - acc: 0.2526 - top_k_categorical_accuracy: 0.5442 - val_loss: 2.8072 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 2.64246\n",
      "Epoch 261/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0351 - acc: 0.2441 - top_k_categorical_accuracy: 0.5412 - val_loss: 2.9881 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 2.64246\n",
      "Epoch 262/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0071 - acc: 0.2498 - top_k_categorical_accuracy: 0.5429 - val_loss: 2.8986 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 2.64246\n",
      "Epoch 263/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0153 - acc: 0.2535 - top_k_categorical_accuracy: 0.5500 - val_loss: 2.7082 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 2.64246\n",
      "Epoch 264/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0079 - acc: 0.2437 - top_k_categorical_accuracy: 0.5482 - val_loss: 2.7710 - val_acc: 0.3750 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 2.64246\n",
      "Epoch 265/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0022 - acc: 0.2489 - top_k_categorical_accuracy: 0.5441 - val_loss: 2.8374 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 2.64246\n",
      "Epoch 266/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0190 - acc: 0.2484 - top_k_categorical_accuracy: 0.5430 - val_loss: 2.8875 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 2.64246\n",
      "Epoch 267/1000\n",
      "144/144 [==============================] - 249s 2s/step - loss: 3.0674 - acc: 0.2403 - top_k_categorical_accuracy: 0.5349 - val_loss: 3.0540 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 2.64246\n",
      "Epoch 268/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0205 - acc: 0.2539 - top_k_categorical_accuracy: 0.5465 - val_loss: 2.8448 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 2.64246\n",
      "Epoch 269/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 248s 2s/step - loss: 3.0201 - acc: 0.2497 - top_k_categorical_accuracy: 0.5444 - val_loss: 2.9869 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 2.64246\n",
      "Epoch 270/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0220 - acc: 0.2525 - top_k_categorical_accuracy: 0.5467 - val_loss: 2.9312 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 2.64246\n",
      "Epoch 271/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0104 - acc: 0.2552 - top_k_categorical_accuracy: 0.5483 - val_loss: 2.9468 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 2.64246\n",
      "Epoch 272/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0018 - acc: 0.2500 - top_k_categorical_accuracy: 0.5487 - val_loss: 2.6270 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00272: val_loss improved from 2.64246 to 2.62700, saving model to out/checkpoints/1907191034/272-2.627.hdf5\n",
      "Epoch 273/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0241 - acc: 0.2427 - top_k_categorical_accuracy: 0.5390 - val_loss: 2.7221 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 2.62700\n",
      "Epoch 274/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0226 - acc: 0.2538 - top_k_categorical_accuracy: 0.5442 - val_loss: 3.0638 - val_acc: 0.3906 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 2.62700\n",
      "Epoch 275/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0340 - acc: 0.2458 - top_k_categorical_accuracy: 0.5418 - val_loss: 2.7589 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 2.62700\n",
      "Epoch 276/1000\n",
      "144/144 [==============================] - 247s 2s/step - loss: 3.0045 - acc: 0.2552 - top_k_categorical_accuracy: 0.5424 - val_loss: 3.0006 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 2.62700\n",
      "Epoch 277/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0280 - acc: 0.2483 - top_k_categorical_accuracy: 0.5509 - val_loss: 2.8366 - val_acc: 0.3594 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 2.62700\n",
      "Epoch 278/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0349 - acc: 0.2495 - top_k_categorical_accuracy: 0.5454 - val_loss: 3.0308 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 2.62700\n",
      "Epoch 279/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0320 - acc: 0.2463 - top_k_categorical_accuracy: 0.5476 - val_loss: 3.0286 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 2.62700\n",
      "Epoch 280/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0442 - acc: 0.2360 - top_k_categorical_accuracy: 0.5399 - val_loss: 3.0863 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 2.62700\n",
      "Epoch 281/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0550 - acc: 0.2470 - top_k_categorical_accuracy: 0.5369 - val_loss: 2.8779 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 2.62700\n",
      "Epoch 282/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0145 - acc: 0.2552 - top_k_categorical_accuracy: 0.5554 - val_loss: 2.8672 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 2.62700\n",
      "Epoch 283/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0377 - acc: 0.2449 - top_k_categorical_accuracy: 0.5428 - val_loss: 3.1600 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 2.62700\n",
      "Epoch 284/1000\n",
      "144/144 [==============================] - 248s 2s/step - loss: 2.9810 - acc: 0.2579 - top_k_categorical_accuracy: 0.5547 - val_loss: 2.8383 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 2.62700\n",
      "Epoch 285/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0091 - acc: 0.2528 - top_k_categorical_accuracy: 0.5450 - val_loss: 2.9966 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 2.62700\n",
      "Epoch 286/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0220 - acc: 0.2454 - top_k_categorical_accuracy: 0.5368 - val_loss: 2.8680 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 2.62700\n",
      "Epoch 287/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0302 - acc: 0.2472 - top_k_categorical_accuracy: 0.5500 - val_loss: 3.2266 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 2.62700\n",
      "Epoch 288/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0107 - acc: 0.2434 - top_k_categorical_accuracy: 0.5449 - val_loss: 3.2391 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 2.62700\n",
      "Epoch 289/1000\n",
      "144/144 [==============================] - 248s 2s/step - loss: 3.0506 - acc: 0.2402 - top_k_categorical_accuracy: 0.5385 - val_loss: 3.1269 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 2.62700\n",
      "Epoch 290/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0172 - acc: 0.2450 - top_k_categorical_accuracy: 0.5480 - val_loss: 2.9361 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 2.62700\n",
      "Epoch 291/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0265 - acc: 0.2470 - top_k_categorical_accuracy: 0.5388 - val_loss: 2.9996 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 2.62700\n",
      "Epoch 292/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0065 - acc: 0.2521 - top_k_categorical_accuracy: 0.5488 - val_loss: 3.0564 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 2.62700\n",
      "Epoch 293/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 2.9956 - acc: 0.2553 - top_k_categorical_accuracy: 0.5526 - val_loss: 2.9817 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 2.62700\n",
      "Epoch 294/1000\n",
      "144/144 [==============================] - 367s 3s/step - loss: 3.0443 - acc: 0.2462 - top_k_categorical_accuracy: 0.5346 - val_loss: 2.9866 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 2.62700\n",
      "Epoch 295/1000\n",
      "144/144 [==============================] - 434s 3s/step - loss: 3.0060 - acc: 0.2486 - top_k_categorical_accuracy: 0.5450 - val_loss: 2.8382 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 2.62700\n",
      "Epoch 296/1000\n",
      "144/144 [==============================] - 437s 3s/step - loss: 3.0127 - acc: 0.2530 - top_k_categorical_accuracy: 0.5431 - val_loss: 2.8951 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 2.62700\n",
      "Epoch 297/1000\n",
      "144/144 [==============================] - 440s 3s/step - loss: 2.9949 - acc: 0.2544 - top_k_categorical_accuracy: 0.5548 - val_loss: 2.9776 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 2.62700\n",
      "Epoch 298/1000\n",
      "144/144 [==============================] - 433s 3s/step - loss: 2.9902 - acc: 0.2573 - top_k_categorical_accuracy: 0.5507 - val_loss: 2.7618 - val_acc: 0.3594 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 2.62700\n",
      "Epoch 299/1000\n",
      "144/144 [==============================] - 440s 3s/step - loss: 2.9687 - acc: 0.2612 - top_k_categorical_accuracy: 0.5535 - val_loss: 2.8674 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.6094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00299: val_loss did not improve from 2.62700\n",
      "Epoch 300/1000\n",
      "144/144 [==============================] - 435s 3s/step - loss: 3.0123 - acc: 0.2571 - top_k_categorical_accuracy: 0.5463 - val_loss: 2.8206 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 2.62700\n",
      "Epoch 301/1000\n",
      "144/144 [==============================] - 435s 3s/step - loss: 3.0129 - acc: 0.2491 - top_k_categorical_accuracy: 0.5414 - val_loss: 2.9146 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 2.62700\n",
      "Epoch 302/1000\n",
      "144/144 [==============================] - 429s 3s/step - loss: 2.9655 - acc: 0.2568 - top_k_categorical_accuracy: 0.5550 - val_loss: 3.0741 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 2.62700\n",
      "Epoch 303/1000\n",
      "144/144 [==============================] - 437s 3s/step - loss: 3.0055 - acc: 0.2491 - top_k_categorical_accuracy: 0.5535 - val_loss: 2.8968 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 2.62700\n",
      "Epoch 304/1000\n",
      "144/144 [==============================] - 433s 3s/step - loss: 2.9966 - acc: 0.2567 - top_k_categorical_accuracy: 0.5521 - val_loss: 2.8364 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 2.62700\n",
      "Epoch 305/1000\n",
      "144/144 [==============================] - 436s 3s/step - loss: 2.9616 - acc: 0.2655 - top_k_categorical_accuracy: 0.5598 - val_loss: 2.6663 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 2.62700\n",
      "Epoch 306/1000\n",
      "144/144 [==============================] - 429s 3s/step - loss: 2.9968 - acc: 0.2595 - top_k_categorical_accuracy: 0.5571 - val_loss: 2.9044 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 2.62700\n",
      "Epoch 307/1000\n",
      "144/144 [==============================] - 425s 3s/step - loss: 3.0115 - acc: 0.2454 - top_k_categorical_accuracy: 0.5497 - val_loss: 3.2054 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 2.62700\n",
      "Epoch 308/1000\n",
      "144/144 [==============================] - 419s 3s/step - loss: 3.0118 - acc: 0.2544 - top_k_categorical_accuracy: 0.5429 - val_loss: 3.1431 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 2.62700\n",
      "Epoch 309/1000\n",
      "144/144 [==============================] - 432s 3s/step - loss: 3.0196 - acc: 0.2451 - top_k_categorical_accuracy: 0.5487 - val_loss: 2.9714 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 2.62700\n",
      "Epoch 310/1000\n",
      "144/144 [==============================] - 424s 3s/step - loss: 2.9983 - acc: 0.2573 - top_k_categorical_accuracy: 0.5503 - val_loss: 3.2052 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 2.62700\n",
      "Epoch 311/1000\n",
      "144/144 [==============================] - 428s 3s/step - loss: 2.9931 - acc: 0.2568 - top_k_categorical_accuracy: 0.5513 - val_loss: 2.8695 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 2.62700\n",
      "Epoch 312/1000\n",
      "144/144 [==============================] - 436s 3s/step - loss: 3.0123 - acc: 0.2490 - top_k_categorical_accuracy: 0.5481 - val_loss: 2.9836 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 2.62700\n",
      "Epoch 313/1000\n",
      "144/144 [==============================] - 436s 3s/step - loss: 3.0021 - acc: 0.2576 - top_k_categorical_accuracy: 0.5508 - val_loss: 2.7871 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 2.62700\n",
      "Epoch 314/1000\n",
      "144/144 [==============================] - 441s 3s/step - loss: 3.0030 - acc: 0.2566 - top_k_categorical_accuracy: 0.5531 - val_loss: 3.0771 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 2.62700\n",
      "Epoch 315/1000\n",
      "144/144 [==============================] - 440s 3s/step - loss: 2.9865 - acc: 0.2551 - top_k_categorical_accuracy: 0.5534 - val_loss: 2.9686 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 2.62700\n",
      "Epoch 316/1000\n",
      "144/144 [==============================] - 431s 3s/step - loss: 2.9381 - acc: 0.2664 - top_k_categorical_accuracy: 0.5667 - val_loss: 2.8500 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 2.62700\n",
      "Epoch 317/1000\n",
      "144/144 [==============================] - 431s 3s/step - loss: 2.9905 - acc: 0.2540 - top_k_categorical_accuracy: 0.5559 - val_loss: 2.6248 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00317: val_loss improved from 2.62700 to 2.62483, saving model to out/checkpoints/1907191034/317-2.625.hdf5\n",
      "Epoch 318/1000\n",
      "144/144 [==============================] - 427s 3s/step - loss: 2.9759 - acc: 0.2648 - top_k_categorical_accuracy: 0.5543 - val_loss: 2.5939 - val_acc: 0.3594 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00318: val_loss improved from 2.62483 to 2.59389, saving model to out/checkpoints/1907191034/318-2.594.hdf5\n",
      "Epoch 319/1000\n",
      "144/144 [==============================] - 430s 3s/step - loss: 2.9789 - acc: 0.2579 - top_k_categorical_accuracy: 0.5584 - val_loss: 2.8506 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 2.59389\n",
      "Epoch 320/1000\n",
      "144/144 [==============================] - 440s 3s/step - loss: 3.0113 - acc: 0.2520 - top_k_categorical_accuracy: 0.5450 - val_loss: 3.0671 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 2.59389\n",
      "Epoch 321/1000\n",
      "144/144 [==============================] - 436s 3s/step - loss: 2.9876 - acc: 0.2525 - top_k_categorical_accuracy: 0.5561 - val_loss: 2.9855 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 2.59389\n",
      "Epoch 322/1000\n",
      "144/144 [==============================] - 427s 3s/step - loss: 3.0229 - acc: 0.2558 - top_k_categorical_accuracy: 0.5472 - val_loss: 2.9200 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 2.59389\n",
      "Epoch 323/1000\n",
      "144/144 [==============================] - 439s 3s/step - loss: 3.0214 - acc: 0.2490 - top_k_categorical_accuracy: 0.5455 - val_loss: 3.0984 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 2.59389\n",
      "Epoch 324/1000\n",
      "144/144 [==============================] - 427s 3s/step - loss: 2.9974 - acc: 0.2509 - top_k_categorical_accuracy: 0.5497 - val_loss: 2.7093 - val_acc: 0.3750 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 2.59389\n",
      "Epoch 325/1000\n",
      "144/144 [==============================] - 426s 3s/step - loss: 2.9984 - acc: 0.2629 - top_k_categorical_accuracy: 0.5516 - val_loss: 2.7874 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 2.59389\n",
      "Epoch 326/1000\n",
      "144/144 [==============================] - 439s 3s/step - loss: 3.0341 - acc: 0.2515 - top_k_categorical_accuracy: 0.5398 - val_loss: 2.9454 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 2.59389\n",
      "Epoch 327/1000\n",
      "144/144 [==============================] - 436s 3s/step - loss: 3.0519 - acc: 0.2456 - top_k_categorical_accuracy: 0.5378 - val_loss: 3.1674 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 2.59389\n",
      "Epoch 328/1000\n",
      "144/144 [==============================] - 428s 3s/step - loss: 3.0160 - acc: 0.2510 - top_k_categorical_accuracy: 0.5505 - val_loss: 2.9198 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 2.59389\n",
      "Epoch 329/1000\n",
      "144/144 [==============================] - 435s 3s/step - loss: 3.0294 - acc: 0.2587 - top_k_categorical_accuracy: 0.5501 - val_loss: 3.0039 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 2.59389\n",
      "Epoch 330/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 434s 3s/step - loss: 3.0075 - acc: 0.2523 - top_k_categorical_accuracy: 0.5455 - val_loss: 2.7576 - val_acc: 0.3594 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 2.59389\n",
      "Epoch 331/1000\n",
      "144/144 [==============================] - 442s 3s/step - loss: 3.0072 - acc: 0.2612 - top_k_categorical_accuracy: 0.5464 - val_loss: 2.8164 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 2.59389\n",
      "Epoch 332/1000\n",
      "144/144 [==============================] - 436s 3s/step - loss: 3.0168 - acc: 0.2525 - top_k_categorical_accuracy: 0.5445 - val_loss: 3.1080 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 2.59389\n",
      "Epoch 333/1000\n",
      "144/144 [==============================] - 436s 3s/step - loss: 3.0030 - acc: 0.2541 - top_k_categorical_accuracy: 0.5456 - val_loss: 3.1393 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 2.59389\n",
      "Epoch 334/1000\n",
      "144/144 [==============================] - 429s 3s/step - loss: 3.0080 - acc: 0.2577 - top_k_categorical_accuracy: 0.5527 - val_loss: 3.1143 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.4375\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 2.59389\n",
      "Epoch 335/1000\n",
      "144/144 [==============================] - 427s 3s/step - loss: 3.0284 - acc: 0.2504 - top_k_categorical_accuracy: 0.5430 - val_loss: 2.7890 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 2.59389\n",
      "Epoch 336/1000\n",
      "144/144 [==============================] - 435s 3s/step - loss: 2.9799 - acc: 0.2591 - top_k_categorical_accuracy: 0.5528 - val_loss: 2.8792 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 2.59389\n",
      "Epoch 337/1000\n",
      "144/144 [==============================] - 426s 3s/step - loss: 3.0014 - acc: 0.2600 - top_k_categorical_accuracy: 0.5524 - val_loss: 3.0606 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.4531\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 2.59389\n",
      "Epoch 338/1000\n",
      "144/144 [==============================] - 439s 3s/step - loss: 3.0260 - acc: 0.2530 - top_k_categorical_accuracy: 0.5481 - val_loss: 3.0893 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.4688\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 2.59389\n",
      "Epoch 339/1000\n",
      "144/144 [==============================] - 438s 3s/step - loss: 2.9760 - acc: 0.2625 - top_k_categorical_accuracy: 0.5516 - val_loss: 2.8474 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 2.59389\n",
      "Epoch 340/1000\n",
      "144/144 [==============================] - 429s 3s/step - loss: 2.9963 - acc: 0.2547 - top_k_categorical_accuracy: 0.5490 - val_loss: 2.8517 - val_acc: 0.3594 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 2.59389\n",
      "Epoch 341/1000\n",
      "144/144 [==============================] - 433s 3s/step - loss: 2.9848 - acc: 0.2641 - top_k_categorical_accuracy: 0.5544 - val_loss: 2.8181 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 2.59389\n",
      "Epoch 342/1000\n",
      "144/144 [==============================] - 436s 3s/step - loss: 3.0152 - acc: 0.2527 - top_k_categorical_accuracy: 0.5507 - val_loss: 3.0786 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 2.59389\n",
      "Epoch 343/1000\n",
      "144/144 [==============================] - 377s 3s/step - loss: 3.0026 - acc: 0.2599 - top_k_categorical_accuracy: 0.5492 - val_loss: 2.8358 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 2.59389\n",
      "Epoch 344/1000\n",
      "144/144 [==============================] - 334s 2s/step - loss: 3.0326 - acc: 0.2518 - top_k_categorical_accuracy: 0.5460 - val_loss: 2.8969 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 2.59389\n",
      "Epoch 345/1000\n",
      "144/144 [==============================] - 313s 2s/step - loss: 3.0126 - acc: 0.2615 - top_k_categorical_accuracy: 0.5573 - val_loss: 2.9563 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 2.59389\n",
      "Epoch 346/1000\n",
      "144/144 [==============================] - 299s 2s/step - loss: 3.0286 - acc: 0.2568 - top_k_categorical_accuracy: 0.5436 - val_loss: 3.1663 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 2.59389\n",
      "Epoch 347/1000\n",
      "144/144 [==============================] - 279s 2s/step - loss: 3.0426 - acc: 0.2568 - top_k_categorical_accuracy: 0.5486 - val_loss: 2.7350 - val_acc: 0.3750 - val_top_k_categorical_accuracy: 0.7031\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 2.59389\n",
      "Epoch 348/1000\n",
      "144/144 [==============================] - 275s 2s/step - loss: 3.0040 - acc: 0.2528 - top_k_categorical_accuracy: 0.5463 - val_loss: 2.7293 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 2.59389\n",
      "Epoch 349/1000\n",
      "144/144 [==============================] - 262s 2s/step - loss: 3.0265 - acc: 0.2520 - top_k_categorical_accuracy: 0.5477 - val_loss: 3.0954 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 2.59389\n",
      "Epoch 350/1000\n",
      "144/144 [==============================] - 256s 2s/step - loss: 3.0398 - acc: 0.2586 - top_k_categorical_accuracy: 0.5445 - val_loss: 2.8514 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 2.59389\n",
      "Epoch 351/1000\n",
      "144/144 [==============================] - 258s 2s/step - loss: 2.9735 - acc: 0.2591 - top_k_categorical_accuracy: 0.5458 - val_loss: 3.1201 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 2.59389\n",
      "Epoch 352/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0021 - acc: 0.2537 - top_k_categorical_accuracy: 0.5468 - val_loss: 3.2589 - val_acc: 0.2031 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 2.59389\n",
      "Epoch 353/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 2.9864 - acc: 0.2592 - top_k_categorical_accuracy: 0.5501 - val_loss: 3.1878 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 2.59389\n",
      "Epoch 354/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0119 - acc: 0.2563 - top_k_categorical_accuracy: 0.5487 - val_loss: 2.9281 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 2.59389\n",
      "Epoch 355/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 2.9932 - acc: 0.2582 - top_k_categorical_accuracy: 0.5492 - val_loss: 3.1126 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 2.59389\n",
      "Epoch 356/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 2.9906 - acc: 0.2642 - top_k_categorical_accuracy: 0.5472 - val_loss: 3.1046 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 2.59389\n",
      "Epoch 357/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 2.9992 - acc: 0.2499 - top_k_categorical_accuracy: 0.5497 - val_loss: 3.0502 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 2.59389\n",
      "Epoch 358/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0196 - acc: 0.2522 - top_k_categorical_accuracy: 0.5378 - val_loss: 3.0083 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 2.59389\n",
      "Epoch 359/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0182 - acc: 0.2653 - top_k_categorical_accuracy: 0.5471 - val_loss: 3.2658 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 2.59389\n",
      "Epoch 360/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 2.9852 - acc: 0.2586 - top_k_categorical_accuracy: 0.5588 - val_loss: 3.0283 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00360: val_loss did not improve from 2.59389\n",
      "Epoch 361/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0064 - acc: 0.2591 - top_k_categorical_accuracy: 0.5490 - val_loss: 2.9458 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 2.59389\n",
      "Epoch 362/1000\n",
      "144/144 [==============================] - 247s 2s/step - loss: 2.9890 - acc: 0.2599 - top_k_categorical_accuracy: 0.5449 - val_loss: 2.6147 - val_acc: 0.3906 - val_top_k_categorical_accuracy: 0.7031\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 2.59389\n",
      "Epoch 363/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0296 - acc: 0.2531 - top_k_categorical_accuracy: 0.5413 - val_loss: 2.9405 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 2.59389\n",
      "Epoch 364/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0344 - acc: 0.2563 - top_k_categorical_accuracy: 0.5463 - val_loss: 3.1709 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 2.59389\n",
      "Epoch 365/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0219 - acc: 0.2558 - top_k_categorical_accuracy: 0.5477 - val_loss: 3.0304 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 2.59389\n",
      "Epoch 366/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 2.9967 - acc: 0.2571 - top_k_categorical_accuracy: 0.5524 - val_loss: 2.9595 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 2.59389\n",
      "Epoch 367/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0167 - acc: 0.2517 - top_k_categorical_accuracy: 0.5462 - val_loss: 3.1324 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 2.59389\n",
      "Epoch 368/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 2.9669 - acc: 0.2629 - top_k_categorical_accuracy: 0.5541 - val_loss: 3.1401 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 2.59389\n",
      "Epoch 369/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.0317 - acc: 0.2609 - top_k_categorical_accuracy: 0.5463 - val_loss: 2.8021 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 2.59389\n",
      "Epoch 370/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0284 - acc: 0.2560 - top_k_categorical_accuracy: 0.5429 - val_loss: 2.8364 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 2.59389\n",
      "Epoch 371/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0362 - acc: 0.2555 - top_k_categorical_accuracy: 0.5441 - val_loss: 2.9836 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 2.59389\n",
      "Epoch 372/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0076 - acc: 0.2588 - top_k_categorical_accuracy: 0.5460 - val_loss: 2.7350 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 2.59389\n",
      "Epoch 373/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0089 - acc: 0.2587 - top_k_categorical_accuracy: 0.5508 - val_loss: 2.7226 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.6562\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 2.59389\n",
      "Epoch 374/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0646 - acc: 0.2470 - top_k_categorical_accuracy: 0.5359 - val_loss: 3.2182 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 2.59389\n",
      "Epoch 375/1000\n",
      "144/144 [==============================] - 257s 2s/step - loss: 3.0572 - acc: 0.2499 - top_k_categorical_accuracy: 0.5359 - val_loss: 3.1909 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 2.59389\n",
      "Epoch 376/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.0298 - acc: 0.2526 - top_k_categorical_accuracy: 0.5449 - val_loss: 3.0898 - val_acc: 0.3750 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 2.59389\n",
      "Epoch 377/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0164 - acc: 0.2561 - top_k_categorical_accuracy: 0.5456 - val_loss: 3.3270 - val_acc: 0.1875 - val_top_k_categorical_accuracy: 0.4062\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 2.59389\n",
      "Epoch 378/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0100 - acc: 0.2649 - top_k_categorical_accuracy: 0.5505 - val_loss: 2.9024 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 2.59389\n",
      "Epoch 379/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0066 - acc: 0.2588 - top_k_categorical_accuracy: 0.5521 - val_loss: 2.9591 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 2.59389\n",
      "Epoch 380/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.0256 - acc: 0.2622 - top_k_categorical_accuracy: 0.5429 - val_loss: 2.7448 - val_acc: 0.3906 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 2.59389\n",
      "Epoch 381/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 3.0248 - acc: 0.2566 - top_k_categorical_accuracy: 0.5476 - val_loss: 3.1213 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 2.59389\n",
      "Epoch 382/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0584 - acc: 0.2478 - top_k_categorical_accuracy: 0.5341 - val_loss: 3.0864 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 2.59389\n",
      "Epoch 383/1000\n",
      "144/144 [==============================] - 249s 2s/step - loss: 3.0439 - acc: 0.2432 - top_k_categorical_accuracy: 0.5369 - val_loss: 2.8550 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 2.59389\n",
      "Epoch 384/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0415 - acc: 0.2512 - top_k_categorical_accuracy: 0.5383 - val_loss: 2.8711 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 2.59389\n",
      "Epoch 385/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0212 - acc: 0.2566 - top_k_categorical_accuracy: 0.5444 - val_loss: 3.0020 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 2.59389\n",
      "Epoch 386/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0132 - acc: 0.2581 - top_k_categorical_accuracy: 0.5486 - val_loss: 2.9686 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 2.59389\n",
      "Epoch 387/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0352 - acc: 0.2556 - top_k_categorical_accuracy: 0.5395 - val_loss: 3.0580 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 2.59389\n",
      "Epoch 388/1000\n",
      "144/144 [==============================] - 255s 2s/step - loss: 2.9879 - acc: 0.2551 - top_k_categorical_accuracy: 0.5513 - val_loss: 3.0408 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 2.59389\n",
      "Epoch 389/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0058 - acc: 0.2576 - top_k_categorical_accuracy: 0.5459 - val_loss: 3.0707 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 2.59389\n",
      "Epoch 390/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0555 - acc: 0.2556 - top_k_categorical_accuracy: 0.5343 - val_loss: 3.2659 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 2.59389\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144/144 [==============================] - 254s 2s/step - loss: 3.0494 - acc: 0.2536 - top_k_categorical_accuracy: 0.5395 - val_loss: 3.3374 - val_acc: 0.1250 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 2.59389\n",
      "Epoch 392/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0435 - acc: 0.2522 - top_k_categorical_accuracy: 0.5360 - val_loss: 2.9612 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.6094\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 2.59389\n",
      "Epoch 393/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0192 - acc: 0.2552 - top_k_categorical_accuracy: 0.5433 - val_loss: 2.7716 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 2.59389\n",
      "Epoch 394/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0382 - acc: 0.2549 - top_k_categorical_accuracy: 0.5375 - val_loss: 2.9710 - val_acc: 0.3281 - val_top_k_categorical_accuracy: 0.6719\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 2.59389\n",
      "Epoch 395/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0471 - acc: 0.2624 - top_k_categorical_accuracy: 0.5408 - val_loss: 3.2770 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 2.59389\n",
      "Epoch 396/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0310 - acc: 0.2589 - top_k_categorical_accuracy: 0.5385 - val_loss: 3.1634 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 2.59389\n",
      "Epoch 397/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0379 - acc: 0.2527 - top_k_categorical_accuracy: 0.5357 - val_loss: 3.4616 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 2.59389\n",
      "Epoch 398/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0549 - acc: 0.2444 - top_k_categorical_accuracy: 0.5381 - val_loss: 3.0852 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5625\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 2.59389\n",
      "Epoch 399/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0548 - acc: 0.2533 - top_k_categorical_accuracy: 0.5327 - val_loss: 3.1008 - val_acc: 0.2188 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 2.59389\n",
      "Epoch 400/1000\n",
      "144/144 [==============================] - 253s 2s/step - loss: 3.0024 - acc: 0.2609 - top_k_categorical_accuracy: 0.5521 - val_loss: 2.9023 - val_acc: 0.3438 - val_top_k_categorical_accuracy: 0.6406\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 2.59389\n",
      "Epoch 401/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0266 - acc: 0.2649 - top_k_categorical_accuracy: 0.5454 - val_loss: 3.0521 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 2.59389\n",
      "Epoch 402/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0426 - acc: 0.2535 - top_k_categorical_accuracy: 0.5405 - val_loss: 3.2823 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 2.59389\n",
      "Epoch 403/1000\n",
      "144/144 [==============================] - 254s 2s/step - loss: 3.0423 - acc: 0.2564 - top_k_categorical_accuracy: 0.5416 - val_loss: 2.8974 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 2.59389\n",
      "Epoch 404/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0426 - acc: 0.2520 - top_k_categorical_accuracy: 0.5419 - val_loss: 3.4116 - val_acc: 0.1719 - val_top_k_categorical_accuracy: 0.4844\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 2.59389\n",
      "Epoch 405/1000\n",
      "144/144 [==============================] - 251s 2s/step - loss: 3.0546 - acc: 0.2466 - top_k_categorical_accuracy: 0.5374 - val_loss: 2.8945 - val_acc: 0.3125 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 2.59389\n",
      "Epoch 406/1000\n",
      "144/144 [==============================] - 247s 2s/step - loss: 3.0377 - acc: 0.2620 - top_k_categorical_accuracy: 0.5397 - val_loss: 2.9782 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5938\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 2.59389\n",
      "Epoch 407/1000\n",
      "144/144 [==============================] - 248s 2s/step - loss: 3.0027 - acc: 0.2548 - top_k_categorical_accuracy: 0.5465 - val_loss: 3.0057 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.6250\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 2.59389\n",
      "Epoch 408/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0570 - acc: 0.2552 - top_k_categorical_accuracy: 0.5370 - val_loss: 3.1163 - val_acc: 0.2656 - val_top_k_categorical_accuracy: 0.5469\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 2.59389\n",
      "Epoch 409/1000\n",
      "144/144 [==============================] - 249s 2s/step - loss: 3.0459 - acc: 0.2471 - top_k_categorical_accuracy: 0.5371 - val_loss: 3.2439 - val_acc: 0.2500 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 2.59389\n",
      "Epoch 410/1000\n",
      "144/144 [==============================] - 249s 2s/step - loss: 3.0491 - acc: 0.2547 - top_k_categorical_accuracy: 0.5449 - val_loss: 2.9362 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5781\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 2.59389\n",
      "Epoch 411/1000\n",
      "144/144 [==============================] - 252s 2s/step - loss: 3.0351 - acc: 0.2524 - top_k_categorical_accuracy: 0.5385 - val_loss: 2.8345 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.6875\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 2.59389\n",
      "Epoch 412/1000\n",
      "144/144 [==============================] - 249s 2s/step - loss: 3.0344 - acc: 0.2580 - top_k_categorical_accuracy: 0.5423 - val_loss: 3.2066 - val_acc: 0.1562 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 2.59389\n",
      "Epoch 413/1000\n",
      "144/144 [==============================] - 250s 2s/step - loss: 3.0128 - acc: 0.2590 - top_k_categorical_accuracy: 0.5525 - val_loss: 3.1910 - val_acc: 0.2812 - val_top_k_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 2.59389\n",
      "Epoch 414/1000\n",
      "144/144 [==============================] - 246s 2s/step - loss: 3.0823 - acc: 0.2426 - top_k_categorical_accuracy: 0.5350 - val_loss: 3.2793 - val_acc: 0.2344 - val_top_k_categorical_accuracy: 0.5156\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 2.59389\n",
      "Epoch 415/1000\n",
      "144/144 [==============================] - 248s 2s/step - loss: 3.0442 - acc: 0.2517 - top_k_categorical_accuracy: 0.5340 - val_loss: 3.3599 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.5312\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 2.59389\n",
      "Epoch 416/1000\n",
      "144/144 [==============================] - 249s 2s/step - loss: 3.0311 - acc: 0.2548 - top_k_categorical_accuracy: 0.5438 - val_loss: 2.8637 - val_acc: 0.2969 - val_top_k_categorical_accuracy: 0.7031\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 2.59389\n"
     ]
    }
   ],
   "source": [
    "# Fit!\n",
    "if load_to_memory:\n",
    "    # Use standard fit.\n",
    "    temporal_cnn.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, csv_logger],\n",
    "            epochs=nb_epoch)\n",
    "else:\n",
    "    # Use fit generator.\n",
    "    temporal_cnn.model.fit_generator(\n",
    "            generator=generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=1,\n",
    "            callbacks=[tb, early_stopper, csv_logger, checkpointer, lr_schedule],\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=1,\n",
    "            max_queue_size=20,\n",
    "            workers=1,\n",
    "            use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
